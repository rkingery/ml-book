{
 "cells": [
  {
   "cell_type": "raw",
   "id": "93fa1b59",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Arrays and Vectorization\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7130422",
   "metadata": {},
   "source": [
    "In this lesson I'll continue on with numerical computing by discussing the topic of arrays and vectorization, which is the use of efficient array operations to speed up computations. Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736f0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "import numpy as np\n",
    "from utils.math_ml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf891dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b897092d",
   "metadata": {},
   "source": [
    "## Array Computing\n",
    "\n",
    "In machine learning and most of scientific computing we're not interested in operating on just single numbers at a time, but many numbers at a time. This is done using *array operations*. The most popular library in python for doing numerical computation on arrays is numpy. \n",
    "\n",
    "Why not just do numerical computations in base python? After all, if we have large arrays of data we can just put them in a list. Consider the following example. Suppose we have two tables of data, $\\mathbf{A}$ and $\\mathbf{B}$. Each table has $m=10$ rows and $n=3$ columns. The rows represent samples, e.g. measured in a lab, and the columns represent the variables, or *features*, being measured, call them $x$, $y$, and $z$, if you like. I'll define these two tables using python lists `A` and `B` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882737f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "A = [[3.5, 18.1, 0.3],\n",
    "     [-8.7, 3.2, 0.5],\n",
    "     [-1.3, 8.4, 0.2],\n",
    "     [5.6, 12.9, 0.9],\n",
    "     [-6.8, 19.7, 0.7],\n",
    "     [7.1, 14.3, 0.1],\n",
    "     [-2.4, 7.6, 0.6],\n",
    "     [4.9, 11.2, 0.8],\n",
    "     [-5.2, 9.8, 0.4],\n",
    "     [0.1, 20.0, 0.2]]\n",
    "\n",
    "B = [[-9.7, 12.5, 0.1],\n",
    "     [-5.1, 14.1, 0.6],\n",
    "     [-1.6, 3.7, 0.7],\n",
    "     [2.3, 19.3, 0.9],\n",
    "     [8.2, 9.7, 0.2],\n",
    "     [-7.9, 4.8, 0.5],\n",
    "     [-4.4, 0.6, 0.4],\n",
    "     [-0.3, 7.1, 0.8],\n",
    "     [3.8, 20.2, 0.3],\n",
    "     [9.4, 16.9, 0.1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f8a83",
   "metadata": {},
   "source": [
    "Suppose we wanted to add the elements in these two tables together, index by index, like this,\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "A[0][0] + B[0][0], & A[0][1] + B[0][1], & \\cdots, & A[0][2] + B[0][2] \\\\\n",
    "A[1][0] + B[1][0], & A[1][1] + B[1][1], & \\cdots, & A[1][2] + B[1][2] \\\\\n",
    "\\cdots,    & \\cdots,    &  \\cdots,  & \\cdots  \\\\\n",
    "A[9][0] + B[9][0], & A[9][1] + B[9][1], & \\cdots, & A[9][2] + B[9][2] \\\\\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "If we wanted to do this in python, we'd have to loop over all rows and columns and place the sums one-by-one inside an array $\\mathbf{C}$, like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0fbf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arrays(A, B):\n",
    "    n_rows, n_cols = len(A), len(A[0])\n",
    "    C = []\n",
    "    for i in range(n_rows):\n",
    "        row = []\n",
    "        for j in range(n_cols):\n",
    "            x = A[i][j] + B[i][j]\n",
    "            row.append(x)\n",
    "        C.append(row)\n",
    "    return C\n",
    "\n",
    "C = add_arrays(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da12c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-6.2, 30.6, 0.4],\n",
       " [-13.8, 17.3, 1.1],\n",
       " [-2.9, 12.1, 0.9],\n",
       " [7.9, 32.2, 1.8],\n",
       " [1.4, 29.4, 0.9],\n",
       " [-0.8, 19.1, 0.6],\n",
       " [-6.8, 8.2, 1.0],\n",
       " [4.6, 18.3, 1.6],\n",
       " [-1.4, 30.0, 0.7],\n",
       " [9.5, 36.9, 0.3]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "np.array(C).round(2).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b6f56",
   "metadata": {},
   "source": [
    "Numpy makes this far easier to do. It implements *element-wise* array operatations, which allow us to operate on arrays with far fewer lines of code. In numpy, to perform the same adding operation we just did, we'd just add the two arrays together directly, $\\mathbf{A}+\\mathbf{B}$.\n",
    "\n",
    "To use numpy operations we have to convert data into the native numpy data type, the numpy array. Do this by wrapping lists inside the function `np.array`. Once we've done this, we can just add them together in one line. This will simultaneously element-wise add the elements in the array so we don't have to loop over anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e365ff1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = \n",
      "[[ -6.2  30.6   0.4]\n",
      " [-13.8  17.3   1.1]\n",
      " [ -2.9  12.1   0.9]\n",
      " [  7.9  32.2   1.8]\n",
      " [  1.4  29.4   0.9]\n",
      " [ -0.8  19.1   0.6]\n",
      " [ -6.8   8.2   1. ]\n",
      " [  4.6  18.3   1.6]\n",
      " [ -1.4  30.    0.7]\n",
      " [  9.5  36.9   0.3]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array(A)\n",
    "B = np.array(B)\n",
    "print(f'C = \\n{A+B}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8e917",
   "metadata": {},
   "source": [
    "This is really nice. We've managed to reduce a double foor loop of 8 lines of code down to just 1 line with no loops at all. Of course, there *are* loops happening in the background inside the numpy code, we just don't see them.\n",
    "\n",
    "Numpy lets us do this with pretty much any arithmetic operation we can think of. We can element-wise add, subtract, multiply, or divide the two arrays. We can raise them to powers, exponentiate them, take their logarithms, etc. Just like we would do so with single numbers. In numpy, arrays become first class citizens, treated on the same footing as the simpler numerical data types `int` and `float`. This is called **vectorization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7e703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A - B;\n",
    "A * B;\n",
    "A / B;\n",
    "A ** 2;\n",
    "np.abs(A) ** B;\n",
    "np.exp(A);\n",
    "np.sin(A);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96e24f",
   "metadata": {},
   "source": [
    "If vectorization just made code easier to read it would be a nice to have. But it's more than this. In fact, vectorization also makes your code run much faster in many cases. Let's see an example of this. I'll again run the same operations above to add two arrays, but this time I'm going to **profile** the code in each case. That is, I'm going to time each operation over several runs and average the times. The ones with the lowest average time is faster than the slower one, obviously. To profile in a notebook, the easiest way is to use the `%timeit` magic command, which will do all this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088ad1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.24 µs ± 158 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "A = A.tolist()\n",
    "B = B.tolist()\n",
    "%timeit C = add_arrays(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b8dce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409 ns ± 1.15 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "A = np.array(A)\n",
    "B = np.array(B)\n",
    "%timeit C = A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489383f",
   "metadata": {},
   "source": [
    "Even with these small arrays the numpy vectorized array addition is almost 10 times faster than the python loop array addition. This difference becomes much more pronounced when arrays are larger. The arrays just considered are only of shape $(10,3)$. We can easily confirm this in numpy using the methods `A.shape` and `B.shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86504552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape = (10, 3)\n",
      "B.shape = (10, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'A.shape = {A.shape}')\n",
    "print(f'B.shape = {B.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ac08c2",
   "metadata": {},
   "source": [
    "Let's try to run the add operations on much larger arrays of shape $(10000,100)$. To do this quickly I'll use `np.random.rand(shape)`, which will sample an array with shape `shape` whose values are uniformly between 0 and 1. More on sampling in a future lesson. Running the profiling, we're now running about 100 times faster using numpy vectorization compared to python loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "269b7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.random.rand(10000, 100)\n",
    "E = np.random.rand(10000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db9b5d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 ms ± 323 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "D = D.tolist()\n",
    "E = E.tolist()\n",
    "%timeit F = add_arrays(D, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51d9bb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22 ms ± 10 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "D = np.array(D)\n",
    "E = np.array(E)\n",
    "%timeit F = D + E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e86dc27",
   "metadata": {},
   "source": [
    "So why is numpy vectorization so much faster than using native python loops? Because it turns out that numpy by and large doesn't actually perform array operations in python! When array operations are done, numpy compiles them down to low-level C code and runs the operations there, where things are much faster. \n",
    "\n",
    "Not only that, numpy takes advantage of very efficient linear algebra functions written over the course of decades by smart people. These functions come from low-level FORTRAN and C libraries like [BLAS](https://netlib.org/blas/) and [LAPACK](https://netlib.org/lapack/). They're hand-designed to take maximum advantage of computational speed-ups where available. These include things like parallelization, caching, and hardware vectorization operations. Native python doesn't take advantage of *any* of these nice things. The moral is, if you want to run array operations efficiently, you need to use a numerical library like numpy or modern variants like pytorch.\n",
    "\n",
    "### Higher-Dimensional Arrays\n",
    "\n",
    "The number of different dimensions an array has is called its **dimension** or **rank**. Equivalently, the rank or dimension of an array is just the length of its shape tuple. The arrays I showed above are examples of rank-2 or 2-dimensional arrays. We can define arrays with any number of dimensions we like. These arrays of different rank sometimes have special names:\n",
    "\n",
    "- A 0-dimensional (rank-0) array is called a **scalar**. These are single numbers.\n",
    "- A 1-dimensional (rank-1) array is called a **vector**. These are arrays with only one row.\n",
    "- A 2-dimensional (rank-2) array is called a **matrix**. These are arrays with multiple rows.\n",
    "- An array of dimension or rank 3 or higher is called a **tensor**. These are arrays with multiple matrices.\n",
    "\n",
    "More on these when we get to linear algebra. Here are some examples so you can see what they look like. Note I'm using `dtype=np.float64` to explicitly cast the values as float64 when defining the arrays. Numpy's vectorization operations work for all of these arrays regardless of their shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1d6aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = np.float64(5)\n",
    "scalar # 0-dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6995489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector.shape = (3,)\n",
      "vector = [1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "vector = np.array([1, 2, 3], dtype=np.float64)\n",
    "print(f'vector.shape = {vector.shape}')\n",
    "print(f'vector = {vector}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8e5071e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix.shape = (2, 3)\n",
      "matrix = \n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float64)\n",
    "print(f'matrix.shape = {matrix.shape}')\n",
    "print(f'matrix = \\n{matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6912b579",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.shape = (2, 2, 2)\n",
      "tensor = \n",
      "[[[1. 2.]\n",
      "  [3. 4.]]\n",
      "\n",
      " [[5. 6.]\n",
      "  [7. 8.]]]\n"
     ]
    }
   ],
   "source": [
    "tensor = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]], dtype=np.float64)\n",
    "print(f'tensor.shape = {tensor.shape}')\n",
    "print(f'tensor = \\n{tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d56d38",
   "metadata": {},
   "source": [
    "Numpy also supports array aggregation operations as well. Suppose you have a matrix `A` and want to get the sum of the values in each row of `A`. To do this, you could use `np.sum(A, axis=1)`, where `axis` is the index of the dimension you want to sum over (the columns in this case). This will return a vector where the value at index $i$ is the sum of elements in row $i$. To sum over *all* elements in the array, don't pass anything to `axis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6fe7132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [-1., -2., -3.],\n",
       "       [ 1.,  0., -1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2, 3], [-1, -2, -3], [1, 0, -1]], dtype=np.float64)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b80b53e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6., -6.,  0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(A, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d70188b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda00dc1",
   "metadata": {},
   "source": [
    "Indexing into numpy arrays like `A` is more powerful than with python lists. Instead of having to awkwardly index like `A[1][0]`, write `A[1, 0]`. To get all values in column index `1`, write `A[:, 1]`. To get just the first and last row, we could just pass the index we want in as a list like this, `A[[0, -1], :]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a6a9f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 2., -2.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.],\n",
       "       [ 1.,  0., -1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1][0]\n",
    "A[1, 0]\n",
    "A[:, 1]\n",
    "A[[0, -1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bed284",
   "metadata": {},
   "source": [
    "Numpy also supports Boolean masks as indexes. Suppose we want to get all the positive elements `x >= 0` in `A`. We could create a mask `A > 0`, and pass that into `A` as an index to pick out the positive elements only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17cbbafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True],\n",
       "       [False, False, False],\n",
       "       [ True,  True, False]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (A >= 0)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30609442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 1., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b108ea",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting is a set of conventions for doing array operations on arrays with incompatible shapes. This may seem like a strange thing to do, but it turns out knowing how and when to broadcast can make your code much shorter, more readable, and efficient. All modern-day numerical libraries in python support broadcasting, including numpy, pytorch, tensorflow, etc. So it's a useful thing to learn.\n",
    "\n",
    "### Motivation\n",
    "\n",
    "Let's start with a simple example. Suppose we have an array of floats defined below. We'd like to add 1 to every number in the array. How can we do it? One \"pythonic\" way might be to use a list comprehension like so. This will work just fine, but it requires going back and forth between arrays and lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53aaebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [1. 2. 3. 4. 5.]\n",
      "x + 1 = [2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1., 2., 3., 4., 5.])\n",
    "print(f'x = {x}')\n",
    "\n",
    "x_plus_1 = np.array([val + 1 for val in x])\n",
    "print(f'x + 1 = {x_plus_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc2417b",
   "metadata": {},
   "source": [
    "What if we didn't want to go back and forth like that? It is slow after all. Anytime numpy has to handoff back to python or vice versa it's going to slow things down. Another thing we could try is to make a vector of ones of the same size as `x`, then add it to `x`. This is also fine, but it requires defining this extra array of ones just to add 1 to the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac75dd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + 1 = [2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones(len(x))\n",
    "x_plus_1 = x + ones\n",
    "print(f'x + 1 = {x_plus_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96dff9c",
   "metadata": {},
   "source": [
    "We'd *like* to be able to just add 1 to the array like we would with numbers. If `x` were a single number we'd just write `x + 1` to add one to it, right? But technically we can't do this if `x` is an array, since `x` has shape `(5,)` and 1 is just a number with no shape. This is where broadcasting comes in. Broadcasting says let's *define* the operation `x + 1` so that it *means* add 1 to every element of `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5d0129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x + 1 = [2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "x_plus_1 = x + 1\n",
    "print(f'x + 1 = {x_plus_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d3629b",
   "metadata": {},
   "source": [
    "This notation has the advantage of keeping array equations simple, while at the same time keeping all operations in numpy so that they run fast.\n",
    "\n",
    "### Broadcasting Rules\n",
    "\n",
    "Suppose now that we have two arrays `A` and `B` of arbitrary shape and we want to operate on them, e.g. via the operations `+, -, *, /, //, **`. Here are the general broadcasting rules, quoted directly from the [numpy documentation](https://numpy.org/doc/stable/user/basics.broadcasting.html).\n",
    "\n",
    "> **Numpy Documentation**<br><br>When operating on two arrays, numpy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are **compatible** when <br><br>1. they are equal, or<br>2. one of them is 1 <br><br>If these conditions are not met, a `ValueError: operands could not be broadcast together` exception is thrown, indicating that the arrays have **incompatible** shapes. The size of the resulting array is the size that is not 1 along each axis of the inputs.\n",
    "\n",
    "Let's look at an example. First, suppose `A` has shape `(2, 2, 3)` and `B` has shape `(3,)`. Suppose for simplicity that they're both arrays of all ones. Here's what this looks like, with `B` aligned to the right.\n",
    "\n",
    "\\begin{align*}\n",
    "A &:& 2, & & 2, & & 3 \\\\\n",
    "B &:&   & &   & & 3 \\\\\n",
    "\\hline\n",
    "C &:& 2, & & 2, & & 3 \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Here are the broadcasting steps that will take place. Note that only `B` will change in this example. `A` will stay fixed.\n",
    "\n",
    "- Numpy will start in the rightmost dimension, checking if they're equal.\n",
    "- Begin with `A` of shape `(2, 2, 3)` and `B` of shape `(3,)`.\n",
    "- In this case, the rightmost dimension is `3` in both arrays, so we have a match.\n",
    "- Moving left by one, `B` no longer has anymore dimensions, but `A` has two, each `2`. These arrays are thus compatible.\n",
    "- Numpy will now copy `B` to the left in these new dimensions until it has the same shape as `A`.\n",
    "\n",
    "```\n",
    "1. Copy values of B twice to get \n",
    "   B = [[1, 1, 1], [1, 1, 1]] \n",
    "   with shape (2, 3)\n",
    "2. Copy values of B twice to get \n",
    "   B = [[[1, 1, 1], [1, 1, 1]], [[1, 1, 1], [1, 1, 1]]] \n",
    "   with shape (2, 2, 3)\n",
    "```\n",
    "- The shapes of A and B are now equal. The output array `C` will have shape `(2, 2, 3)`.\n",
    "\n",
    "Let's verify this is true on two simple arrays of ones. Let's also print out what `C` looks like. Since only copying is taking place we should just be adding 2 arrays of ones, hence the output should sum 2 arrays of ones, giving one array `C` of twos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd5f8891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape = (2, 2, 3)\n",
      "B.shape = (3,)\n",
      "C.shape = (2, 2, 3)\n",
      "C = \n",
      "[[[2. 2. 2.]\n",
      "  [2. 2. 2.]]\n",
      "\n",
      " [[2. 2. 2.]\n",
      "  [2. 2. 2.]]]\n"
     ]
    }
   ],
   "source": [
    "A = np.ones((2, 2, 3))\n",
    "B = np.ones(3,)\n",
    "print(f'A.shape = {A.shape}')\n",
    "print(f'B.shape = {B.shape}')\n",
    "\n",
    "C = A + B\n",
    "print(f'C.shape = {C.shape}')\n",
    "print(f'C = \\n{C}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41515a2d",
   "metadata": {},
   "source": [
    "Let's do one more example. Suppose now that `A` has shape `(8, 1, 6, 1)` and `B` has shape `(7, 1, 5)`. Here's a table of this case, again with `B` aligned to the right since it has the fewest dimensions.\n",
    "\n",
    "\\begin{align*}\n",
    "A &:& 8, & & 1, & & 6, & & 1 \\\\\n",
    "B &:&    & & 7, & & 1, & & 5 \\\\\n",
    "\\hline\n",
    "C &:& 8, & & 7, & & 6, & & 5 \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Here are the broadcasting steps that will take place.\n",
    "\n",
    "- Starting again from the right, dimensions `1` and `5` don't match. But since `A` has a `1` rule (2) applies, so `A` will broadcast itself (i.e. copy its values) 5 times in this dimension to match `B`. \n",
    "- Moving left by one we get `6` and `1`. Now `B` will broadcast itself in this dimension 6 times to match `A`. \n",
    "- Moving left again we get `1` and `7`. Now `A` will broadcast itself in this dimension 7 times to match `B`. \n",
    "- Last, we get `8` in `A` and `B` is out of dimensions, so `B` will broadcast itself 8 times to match `A`. \n",
    "- The shapes of `A` and `B` are now equal. The output `C` thus has shape `(8, 7, 6, 5)`.\n",
    "\n",
    "Here again is an example on two arrays of ones. Verify that the shapes come out right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68145269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape = (8, 1, 6, 1)\n",
      "B.shape = (7, 1, 5)\n",
      "C.shape = (8, 7, 6, 5)\n"
     ]
    }
   ],
   "source": [
    "A = np.ones((8, 1, 6, 1))\n",
    "B = np.ones((7, 1, 5))\n",
    "print(f'A.shape = {A.shape}')\n",
    "print(f'B.shape = {B.shape}')\n",
    "\n",
    "C = A / B\n",
    "print(f'C.shape = {C.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fdb060",
   "metadata": {},
   "source": [
    "That's pretty much all there is to broadcasting. It's a systematic way of trying to copy the dimensions in each array until they both have the same shape. All this broadcasting is done under the hood for you when you try to operate on two arrays of different shapes. You don't need to do anything but understand *how* the arrays get broadcast together so you can avoid errors in your calculations, sometimes very subtle errors.\n",
    "\n",
    "This can be a bit confusing to understand if you're not used to it. We'll practice broadcasting a good bit so you can get the hang of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced72230",
   "metadata": {},
   "source": [
    "## Computational Performance\n",
    "\n",
    "We're usually interested in writing functions that run not just correctly, but efficiently. We want them to run as quickly as possible, and using as little memory as possible. When dealing with numbers, particularly floats, the usual way to measure how quickly a function will run is by counting **floating point operations**, or **FLOPS** for short. Memory is measured by counting the number of \"words\" each element in the function takes up.\n",
    "\n",
    "Consider a simple example. Suppose we want to element-wise multiply two 1D arrays `x` and `y` each of size $n$ using the following function,\n",
    "\n",
    "```python\n",
    "1. def element_wise_multiply(x, y):\n",
    "2.    n = len(x)\n",
    "3.    z = [x[i] * y[i] for i in range(n)]\n",
    "4.    return z\n",
    "```\n",
    "\n",
    "Let's ask two questions about this function:\n",
    "\n",
    "1. How many FLOPs is the function doing? That is, how many arithmetic operations `+, -, *, /, //, %` did this function execute?\n",
    "2. How many words of memory does the function use, ignoring the inputs, assuming each word has the same word size (e.g. 64 bits)?\n",
    "\n",
    "Starting with (1), let's look at this function and see how many arithmetic operations, or FLOPs, each line is doing. \n",
    "\n",
    "1. The function signature isn't doing any arithmetic, so $0$ FLOPs\n",
    "2. Getting the length of an array isn't doing any arithmetic, so $0$ FLOPs\n",
    "3. Here we're looping over $n$ terms. Each term has a single multiply. So there are $n$ total FLOPs.\n",
    "4. The return statement isn't doing any arithmetic, so $0$ FLOPs\n",
    "\n",
    "What about (2)? Let's count how many words are being stored by each line of the function.\n",
    "\n",
    "1. We'll generally assume the function signature fits in $1$ word of memory. This isn't exactly true, but it's a decent abstraction.\n",
    "2. The length of an array is a single integer that's pre-computed. Since an integer takes one word to store, this line is using $1$ word of memory.\n",
    "3. This line is using a list comprehension to create an array of `n` elements. Since each element is a single number (each of word size $1$) the array takes up $n$ words of memory.\n",
    "4. This line is just returning the variable `z`, which we've already counted, so no extra memory is being used.\n",
    "\n",
    "Putting it all together, the function is doing $0+0+n+0=n$ total FLOPs and using $1 + 1 + n + 0=n+2$ words of memory when inputs are size $n$. \n",
    "\n",
    "Typically, we imagine $n$ to be very large, say $n=10000$ or something like that. When $n$ gets large, the leading term tends to dominate the rest. So for example $n + 2 \\approx n$. Since it's the dominant term that determines almost of all of the function's performance, we typically just drop the other terms and only keep the dominant term, while also ignoring any constant multiples. To indicate this is what we're doing, it's common to use what's called **asymptotic** or **big-O** notation to represent performance. To indicate the leading term of $g(n)$ is of order $f(n)$, we'd write $O(f(n))$. This is called the algorithmic **complexity** of the function. Here are some examples so you can get an idea of how to use this notation:\n",
    "\n",
    "- $n+2$: The dominant term when $n$ gets large is is $n$, so the total complexity is $O(n)$.\n",
    "- $10n^3 + n^2 + 7$: The dominant term is $10n^3$. Dropping constant multiples gets this down to $n^3$. So $O(n^3)$ is the total complexity.\n",
    "- $1 + 5n\\log n$: The dominant term here is $5n\\log n$. Dropping constants gives $O(n \\log n)$ total complexity.\n",
    "- $2^n + 1000n^{1000}\\log n$: The dominant term is the exponential $2^n$, so the total complexity is $O(2^n)$.\n",
    "\n",
    "Here's a general rule of thumb for calculating complexities quickly. Terms on the left will always dominate terms to their right when $n$ is large.\n",
    "\n",
    "$$\\text{factorials} >> \\text{exponents} >> \\text{polynomials} >> \\text{logarithms} >> \\text{constants}.$$\n",
    "\n",
    "In the above example of element-wise multiplication, both FLOPs and memory are $O(n)$. In general, element-wise operations will always be $O(n)$ FLOPS and memory when the inputs are size $n$. This is also true for multi-dimensional arrays containing $n$ *total* elements. For example, element-wise adding two 2D arrays of shape $(m,m)$ will use $O(m^2)$ FLOPs and memory since the arrays contain $n=m \\cdot m$ total elements.\n",
    "\n",
    "As a rough rule of thumb, complexities below $O(n^3)$ are considered efficient. Complexities above $O(n^3)$ are considered slow. The worst case of all is when it's exponential or larger, like $O(2^n)$ or $O(n!)$. In general, we want to make complexities be as low as possible by using a more efficient algorithm that minimizes FLOPs and memory usage. Using FLOPS and memory complexity will allow us to estimate how efficiently machine learning algorithms are running in future lessons. \n",
    "\n",
    "Before finishing up, I'll mention that notions like FLOPs and words of memory are only abstractions to the real things we care about, how long a function *actually* takes to run (like in seconds), and how much memory is *actually* being used (like in bytes). When in doubt, if a function is running too slow, your best bet will be to run a **profiler** on the function to see how long it's taking and how much memory it's using. In jupyter, you can profile your code using one of the following magic commands:\n",
    "\n",
    "- `%timeit`: Runs the code a bunch of times and returns the average time it takes for the line to run. This is useful when you just want to get an idea how long something takes to run.\n",
    "- `%prun`: Runs a profiler on the code and reports various timing statistics on the entire function.\n",
    "- `%lprun`: Runs a profiler on the code, but reports timing statistics line-by-line, so you can see which lines of code are running slow. \n",
    "    - This is the most useful profiler in my opinion since you can see which actual lines are running slow.\n",
    "    - Need to install the `line_profiler` library first and load in the notebook with `%load_ext line_profiler`\n",
    "- `%memit`: Runs a memory profiler on the code, returning statistics on how much memory is being taken up.\n",
    "    - Need to install the `memory_profiler` library first and load in the notebook with `%load_ext memory_profiler`\n",
    "- `%mprun`: Runs a memory profiler on the code, giving line-by-line statistics on how much memory each line is taking up.\n",
    "    - Annoyingly, this only works for functions defined from a python script, not from a notebook\n",
    "    - Need to install the `memory_profiler` library first and load in the notebook with`%load_ext memory_profiler`\n",
    "\n",
    "I'll run each of these profilers on the above function `element_wise_multiply` so you can see how they work. To run it, you first need to pass in some inputs. I'll define some reasonably large arrays for this. Notice, as you'd expect, it's the line defining `z` that's the worst offender. This is the idea that FLOPs and memory complexity already were capturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1695d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "# def element_wise_multiply(x, y):\n",
    "#     n = len(x)\n",
    "#     z = [x[i] * y[i] for i in range(n)]\n",
    "#     return z\n",
    "\n",
    "# n = 10000\n",
    "# x = np.ones(n).tolist()\n",
    "# y = np.ones(n).tolist()\n",
    "\n",
    "# %load_ext line_profiler\n",
    "# %load_ext memory_profiler\n",
    "\n",
    "# %timeit element_wise_multiply\n",
    "\n",
    "# a = %prun -r -s tottime element_wise_multiply(x, y);\n",
    "# a.print_stats()\n",
    "\n",
    "# a = %lprun -r -f element_wise_multiply element_wise_multiply(x, y);\n",
    "# a.print_stats()\n",
    "\n",
    "# %memit element_wise_multiply(x, y);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
