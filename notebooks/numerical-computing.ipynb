{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ec3d6f",
   "metadata": {},
   "source": [
    "## Math for ML: Numerical Computation\n",
    "\n",
    "In this section of Math for ML we'll discuss the basics of numerical computation. This includes what integers and floating point numbers are and how they're represented on a computer, as well as an introduction to numpy and array-based computing.\n",
    "\n",
    "Let's start by talking a bit about numbers and how they're represented on computers. This may seem too basic to mention, but it's actually very important. There's a lot of subtlety involved. Recall that in python and most other languages there are several different *types* of numbers. The most important being integers (ints) and floating point numbers (floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122dd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5f9224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes every line of a cell print instead of just the last line\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f73479",
   "metadata": {},
   "source": [
    "## Integers\n",
    "\n",
    "Integers are whole numbers that can be positive, negative, or zero. Examples are 5, 100151, 0, -72, etc. \n",
    "\n",
    "**Notation:** Math folks like to represent the \"set\" of integers by the \"block Z\" symbol, $\\mathbb{Z}$. To say that \"x is an integer\" we can use the shorthand $x \\in \\mathbb{Z}$.\n",
    "\n",
    "In python, ints are builtin objects of type `int` that more or less follow the rules that integers in math follow.\n",
    "\n",
    "Among other things, the following operations can be performed with integers:\n",
    "- Addition: $2 + 2 = 4$.\n",
    "- Subtraction: $2 - 5 = -3$.\n",
    "- Multiplication: $3 * 3 = 9$.\n",
    "- Exponentiation: $2^3 = 2*2*2 = 8$ (in python this is the `**` operator, e.g. `2 ** 3 = 8`).\n",
    "- Remainder (or Modulo): the remainder of 10 when divided by 3 is 1, written $10 \\text{ mod } 3 = 1$ (in python this is the `%` operator, e.g. `10 % 3 = 1`).\n",
    "\n",
    "If any of these operations are applied to two integers, the output will itself always be an integer.\n",
    "\n",
    "Here are a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae73635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 + 2\n",
    "2 - 5\n",
    "3 * 3\n",
    "10 % 3\n",
    "2 ** 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbd25d",
   "metadata": {},
   "source": [
    "What about division? You can't always divide two integers and get another integer. What you have to do instead is called integer division. Here you divide the two numbers and then round the answer down to the nearest whole number. Since $5 \\div 2 = 2.5$, the nearest rounded down integer is 2. \n",
    "\n",
    "In math, this \"nearest rounded down integer\" 2 is usually called the **floor** of 2.5, and represented with the funny symbol $\\lfloor 2.5 \\rfloor.$ Using this notation we can write the above integer division as \n",
    "$$\\big\\lfloor \\frac{5}{2} \\big\\rfloor = 2.$$\n",
    "\n",
    "In python, integer division is done using the `//` operator, e.g. `5 // 2 = 2`. Thus, I'll usually just write $5 \\ // \\ 2$ instead in this book,\n",
    "$$5 \\ // \\ 2 = \\big\\lfloor \\frac{5}{2} \\big\\rfloor = 2.$$\n",
    "I personally like this notation better than $\\lfloor \\frac{5}{2} \\rfloor$ since it's closer to python, and hence easier to translate to code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b69b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db816a",
   "metadata": {},
   "source": [
    "We can also do regular division `/` with ints, but the output will *not* be an integer even if the answer should be, e.g. `4 / 2`. Only integer division is guaranteed to return an integer. We'll get to this shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "683046fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 / 2\n",
    "type(4 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e637d622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 // 2\n",
    "type (4 // 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0cee34",
   "metadata": {},
   "source": [
    "Division by zero is of course undefined for both division and integer division. In python it will always raise a `ZeroDivisionError` like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52cd06fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/cqjvz_nx0k938fxw3vgvq6v80000gn/T/ipykernel_9231/2293179708.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m4\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "4 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d793253",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3j/cqjvz_nx0k938fxw3vgvq6v80000gn/T/ipykernel_9231/2475120888.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m4\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "4 // 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917090ba",
   "metadata": {},
   "source": [
    "### Representing Ints\n",
    "\n",
    "Just like every other data type, on a computer integers are *actually* represented internally as a sequence of bits. The number of bits used to represent the integer is called its *word size*. In python the typical word size is 64 bits.\n",
    "\n",
    "\n",
    "**Aside:** Since there are $2^{64}$ possible numbers in 64 bits, python *should* only be able to represent $2^{64}$ integers. Assuming integers can be negative, that would mean only integers in the range $[-2^{63}+1, 2^{63}-1]$ should be valid, i.e. only the integers $-2^{63}+1, -2^{63}+2, \\cdots, -1, 0, 1, \\cdots, 2^{63}-2, 2^{63}-1$. This is essentially true in older versions of pythons as well as most older programming languages like C or C++. But it turns out newer versions of python have tricks that allow you to represent essentially arbitrarily large and integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6eed9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1267650600228229401496703205376"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** 63 - 1 # should be the max integer allowed\n",
    "2 ** 100 # but this much bigger number is represented just fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1858bf",
   "metadata": {},
   "source": [
    "This interesting fact aside, integers are represented in bits more or less by their binary representation. For example, consider the integer 6. This is `110` in binary. It would be represented in 64 bits with one bit at the beginning to indicate its sign (in this case `0` since the sign is positive), 63-3=60 bits of leading zeros, and finally the binary sequence `110`. Our representation for the integer 6 thus might look something like this:\n",
    "```\n",
    "0    000000000000000000000000000000000000000000000000000000000000    110\n",
    "sign bit (0=+, 1=-)      60 leading zeros                3 bits for bin(6) = 110\n",
    "```\n",
    "\n",
    "**Aside:** In real life integers are usually represented on a computer using what's called the *two's complement* representation. It's very similar to what I just described, except it handles negative numbers slightly differently by flipping the bits at the end and adding 1. There are advantages to doing it this way, but in my opinion this isn't worth dwelling on in this book.\n",
    "\n",
    "Rather than waste valuable time trying to teach you (or remind you) how to convert numbers to binary and back by hand, I'll just mention that we can easily get the binary representation of an integer in python by using the `bin` function. The `bin` function returns the binary representation of an int as a string beginning with `0b`. To go back to the decimal form just use `int` on the binary string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2598d359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b110'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae5f1e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0b110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629d4a4",
   "metadata": {},
   "source": [
    "It's worth visualizing what integers look like on the number line, if for nothing else than to compare it with what floats look like later on. To do so I'm going to create a fake 6-bit integer system and plot them. These ints will run from $-2^{5}=-32$ to $2^{5}-1=31$. The asymmetry has to do with the inclusion of $0$. The fact that exponent is 5 and not 6 is because the last bit is used for the sign of the integer. \n",
    "\n",
    "To plot these ints I'm going to use the helper function `plot_number_dist`. When plotted, these ints should take equally-spaced discrete dots at each integer from -32 to 31, which is what we see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8478b6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "six_bit_ints = range(-2**5, 2**5)\n",
    "plot_number_dist(six_bit_ints, title='Distribution of 6-bit Ints')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c51e9e",
   "metadata": {},
   "source": [
    "Technically the integers I've described above are what are called **signed integers**. They can be positive or negative. We can also have **unsigned integers**, which are ints that can only be positive. Unsigned ints work basically the same as signed ints, except they don't need the sign bit, so they can use all bits to represent the number itself. \n",
    "\n",
    "Python natively implements ints as signed, and that's usually what we care about. But unsigned ints sometimes show up.\n",
    "For example, a popular choice in recent years is to use 8-bit unsigned ints to encode the parameters of a neural network in a lookup table. This is called model quantization, and is used to make the model take up much less disk space than it otherwise would."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6b9b59",
   "metadata": {},
   "source": [
    "## Floats\n",
    "\n",
    "What if we want decimal numbers or fractions instead of whole numbers, like 1.2 or 0.99999 or 3.1415926 or 1/2? To do this we need a new system of numbers called floating point numbers, or **floats**. Floats are an attempt to represent what in math are called **real numbers**. As we'll see, floats can't represent all real numbers *exactly* because they can't express numbers with arbitrary many digits. Nevertheless, they're a reasonably good approximation to the idea of the real number line.\n",
    "\n",
    "**Notation:** Math folks like to express the set of real numbers using the \"block R\" symbol $\\mathbb{R}$, and write \"x is a real number\" as $x \\in \\mathbb{R}$.\n",
    "\n",
    "In python, floats are builtin objects of type `float`. They approximate real numbers with a given degree of precision (we'll get to this shortly).\n",
    "\n",
    "Floats obey pretty much the same operations that integers do with some minor exceptions:\n",
    "- Addition: $1.2 + 4.3 = 5.5$.\n",
    "- Subtraction: $1.2 - 4.3 = -3.1$.\n",
    "- Multiplication: $1.2 * 4.3 = 5.16$.\n",
    "- Exponentiation: $4.3^2 = 18.49$.\n",
    "- Remainder (or Modulo): $4.3 \\text{ mod } 1.2 = 0.7$.\n",
    "- Integer Division: $4.3 \\ // \\ 1.2 = 3.0$.\n",
    "- Division: $4.3 \\div 1.2$.\n",
    "\n",
    "Let's print these out in python and verify the answers are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7be491cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-3.0999999999999996"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5.159999999999999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18.49"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3.5833333333333335"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2 + 4.3\n",
    "1.2 - 4.3\n",
    "1.2 * 4.3\n",
    "4.3 ** 2\n",
    "4.3 % 1.2\n",
    "4.3 // 1.2\n",
    "4.3 / 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed1212",
   "metadata": {},
   "source": [
    "Most of them look right. But what the heck is going on with `1.2 - 4.3` and `1.2 * 4.3`? We're getting these weird trailing 9s. That gets to how floats are represented on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b43d2d",
   "metadata": {},
   "source": [
    "### Representing Floats\n",
    "\n",
    "So how are floats represented on a computer? By default, python uses what's called **double precision** for floats, which means 64 bits are used to represent a float. This is just like with ints, except there's a major difference in how the number is represented. While ints are represented via their binary sequence, floats are represented in multiple pieces.\n",
    "\n",
    "Generally speaking, a floating point number $x$ can be expressed in the form\n",
    "$$x = (-1)^{\\text{sign}} \\cdot 2^{\\text{exponent}-\\text{bias}} \\cdot \\text{precision},$$\n",
    "where $\\text{sign}$ is the **sign bit** (which can be 0 or 1), while $\\text{exponent}$ and $\\text{precision}$ are values that each take up some number of bits depending on the floating point precision. The **exponent** determines what *power* to raise the float to, which affects the *range* of values the system can take on. The **precision** (or **significand**) determines the actual digits of precision you see. It's the bits used to represent the decimal places in the number essentially. There is also a fixed term called a **bias**, which is meant to control the trade-off between how much precision to show around zero vs larger numbers.\n",
    "\n",
    "In the double precision (64-bit) floating point convention,\n",
    "- 1 bit is used to represent the **sign**, \n",
    "- 11 bits to represent the **exponent**,\n",
    "- the remaining 52 bits are used to represent the **precision**, and\n",
    "- the **bias** is taken to be $1023=2^{10}-1$.\n",
    "\n",
    "On top of all these floats, a few of them are also reserved for special values like positive and negative infinity, positive and negative zero (yes that's a thing), and the \"not-a-number\" or NaN.\n",
    "\n",
    "Some consequence of this representation are:\n",
    "- They can only represent values in the range of about $-10^{308}, \\cdots, 10^{308}$.\n",
    "- They can only express up to about $16$ decimal digits of precision. \n",
    "- For numbers around 0, the smallest possible numbers they can represent are about $\\pm 10^{-308}$.\n",
    "- For larger numbers, the gap between any two floats is at least $10^{-16}$, called **machine epsilon**.\n",
    "- Any number that does not fall into this range either gets truncated to the nearest float or mapped to a special number like zero or infinity.\n",
    "\n",
    "For example, what happens if we try to express the constant $\\pi$ to its first [100 digits](https://www.wolframalpha.com/input?i=pi+to+100+digits) as a double precision float? It just gets truncated to its first 15 digits. Double precision is unable to keep track of the other 85 digits. They just get lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8498ed80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = 3.141592653589793238462643383279502884197169399375105820974944592307816406286208998628034825342117068\n",
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaeb1ef",
   "metadata": {},
   "source": [
    "Another implication of the way floats are defined is that they are not equally spaced. That is, two nearby *small* floats are closer together than two nearby *large* floats. This seems kind of weird, but it's all due to the way the exponents are represented, which makes the smaller numbers have higher precision than larger numbers. Smaller exponents mean that the numbers are closer together, while larger exponents mean that the numbers are further apart.\n",
    "\n",
    "Let's try to visualize this in a plot so it's easier to grasp. To do so, I'll look at the much simpler system of 8-bit floating point. I'll use 3 bits for the precision, 4 for the exponent, and 1 for the sign. I'll also use a bias of 10. \n",
    "\n",
    "I'll generate all possible 8-bit floats using the helper function `gen_all_floats`, passing in the number of precision bits `n_precision=3`, the number of exponent bits `n_exp=4`, and the a bias `bias=10`\n",
    "\n",
    "Let's also print out some statistics to see some properties of this 8-bit floating point system. I'll look at how many numbers there are, the most negative float, the most positive float, the smallest non-zero float, and the machine epsilon.\n",
    "\n",
    "When a number gets larger than the most positive (or negative) float, in this case 56, it's said to **overflow**. Any number larger than this will overflow to infinity (or negative infinity). When a number gets smaller than the the smallest nonzero number, in this case 0.001953125, it's said to **underflow**. Any number smaller than this will truncate down to zero (or negative zero). Overflow and underflow errors are some of the most common numerical bugs that occur in deep learning, and usually result from not handling floats correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd4cf524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of 8-bit floats: 120\n",
      "Most negative float: -56.0\n",
      "Most positive float: 56.0\n",
      "Smallest nonzero float: 0.001953125\n",
      "Machine Epsilon: 0.25\n"
     ]
    }
   ],
   "source": [
    "eight_bit_floats = gen_all_floats(n_precision=3, n_exp=4, bias=10)\n",
    "print(f'Total number of 8-bit floats: {len(eight_bit_floats)}')\n",
    "print(f'Most negative float: {min(eight_bit_floats)}')\n",
    "print(f'Most positive float: {max(eight_bit_floats)}')\n",
    "print(f'Smallest nonzero float: {min([x for x in eight_bit_floats if x > 0])}')\n",
    "print(f'Machine Epsilon: {min([x for x in eight_bit_floats if x > 1]) - 1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0061230",
   "metadata": {},
   "source": [
    "With these numbers in hand let's now plot their distribution on the number line again using the helper function `plot_number_dist` function. Compare with the plot of ints I did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25a2147d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_number_dist(x, title='Distribution of 8-bit Floats')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c2295",
   "metadata": {},
   "source": [
    "Remember, I'm plotting *all* possible 8-bit floating point values here, except the special values $\\pm 0, \\pm \\infty, \\text{NaN}$. What I want you to observe is that we can't even represent all possible numbers in the range $-56, \\cdots, 56$. In fact, not even most of them. For example, the numbers in $-10, \\cdots, 10$ are getting represented *much* more than the ones from $-56, \\cdots, -10$ or $10, \\cdots, 56$. The numbers around $0$ are much closer to each other than the numbers around $\\pm 56$.\n",
    "\n",
    "Feel free to play around with these two functions and see how the distribution of floats changes for different choices of `n_precision`, `n_exp`, and `bias`. Be careful not to make `n_exp` too large though or you may crash the kernel.\n",
    "\n",
    "This same fact is true for double precision numbers, except there are a lot more of them. Doubles can represent a lot more numbers, but they still have gaps. Numbers close to $0$ are much closer together than the ones near the endpoints at around $\\pm 10^{308}$.\n",
    "\n",
    "One practical example where this non-equal spacing issue can become something to worry about is when subtracting two floats of vastly different sizes. For example, the number $10^{100}-1$, written `1e100 - 1` in python, doesn't even exist in double precision. We just get `1e100`. That is, python thinks $10^{100}-1 = 10^{100}$. However, for a much smaller number like $1000$, $1000-1=999$ works just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc41369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e+100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e100 - 1\n",
    "1000 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dce338",
   "metadata": {},
   "source": [
    "There is also a minimum number greater than zero. In double precision, that number is $2^{-1022}$, or about $2 \\cdot 10^{-308}$. In practice, python seems to stop at around $10^{-323}$ as we can see below. This arises from the fact that python also uses something called **subnormal numbers**, which is a way to get slightly better precision around zero. It doesn't change anything we've discussed, it just creates more really small numbers close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "417ccaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-323"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-323\n",
    "1e-324"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38bff46",
   "metadata": {},
   "source": [
    "These issues explain why we got the weird results above when subtracting `1.2 - 4.3`. The imperfect precision in the two numbers resulted in a numerical roundoff error, leading in the trailing 9s that should've rounded up to -3.1 exactly. In fact, subtracting floats is one of the most dangerous operations to do, as it tends to lead to the highest loss of precision in calculations. The closer two numbers are to being equal the worse this loss of precision gets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abfe8f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0999999999999996"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2 - 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a46f8b0",
   "metadata": {},
   "source": [
    "As mentioned, floating point also defines a few special values: $\\pm \\infty$, $\\pm 0$, and $\\text{NaN}$. The infinity values are used to represent values too large to fit into a word size. The zeros are used for numbers too small to round up to the smallest float. The NaN value shows up when a number is undefined. For example, $\\infty - \\infty = \\text{NaN}$ is undefined.\n",
    "\n",
    "In base python these numbers are represented as:\n",
    "- $\\infty$: `float('inf')`, \n",
    "- $\\infty$: `float('-inf')`, \n",
    "- $+0$: `+0`,\n",
    "- $-0$: `-0`,\n",
    "- $\\text{NaN}$: `float('nan')`.\n",
    "\n",
    "These special \"numbers\" show up all the time in machine learning, usually due to some kind of problem during training or some issue with the data, as we'll later see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26726865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float('inf')\n",
    "float('-inf')\n",
    "0\n",
    "-0\n",
    "float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b551ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float('inf') + float('-inf') # infinity - infinity = NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e8d46",
   "metadata": {},
   "source": [
    "There are also other formats for for representing real numbers as well, some not even floating-point based. It turns out there are ways to represent real numbers using **fixed point** numbers instead. In fixed-point systems, numbers are represented in bits by using a certain number for the integer part (left of the decimal), and a certain number for the fractional part (after the decimal). No special attempt is made to represent the exponent. While this allows for a more evenly spaced grid of numbers, it also means you can't represent as wide a range of numbers for a given number of bits. For this reason, fixed point systems usually are not widely used.\n",
    "\n",
    "As far as other floating point representations, while double precision is the python standard, there are other types of precision as well. For example, **single precision** uses 32 bits to represent a real number, while **half precision** uses 16 bits. These floating point formats are less precise than double precision since they can't represent as many numbers, but they do have their uses, as we'll see when we get to deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544e622e",
   "metadata": {},
   "source": [
    "### Common Floating Point Pitfalls\n",
    "\n",
    "To cap this long section on floats, here's a list of common pitfalls people run into when working with floating point numbers, and some ways to avoid each one. This is probably the most important thing to take away from this section. You may find it helpful to reference later on. See this [post](https://www.codeproject.com/Articles/29637/Five-Tips-for-Floating-Point-Programming) for more information.\n",
    "\n",
    "1. Numerical overflow: Letting a number blow up to infinity (or negative infinity)\n",
    "    - Clip numbers from above to keep them from being too large\n",
    "    - Work with the log of the number instead\n",
    "    - Make sure you're not dividing by zero or a really small number\n",
    "    - Normalize numbers so they're all on the same scale\n",
    "2. Numerical underflow: Letting a number spiral down to zero (or negative zero)\n",
    "    - Clip numbers from below to keep them from being too small\n",
    "    - Work with the exp of the number instead\n",
    "    - Normalize numbers so they're all on the same scale\n",
    "3. Subtracting floats: Avoid subtracting two numbers that are approximately equal\n",
    "    - Reorder operations so approximately equal numbers aren't nearby to each other\n",
    "    - Use some algebraic manipulation to recast the problem into a different form\n",
    "    - Avoid differencing squares (e.g. when calculating the standard deviation)\n",
    "4. Testing for equality: Trying to test exact equality of two floats\n",
    "    - Instead of testing `x == y`, test for approximate equality with something like `abs(x - y) <= 1e-5`\n",
    "    - Use functions like `np.allclose(x, y)`, which will do this for you\n",
    "5. Unstable functions: Defining some functions in the naive way instead of in a stable way\n",
    "    - Examples: factorials, softmax, logsumexp\n",
    "    - Use a more stable library implementation of these functions\n",
    "    - Look for the same function but in log form, e.g. `log_factorial` or `log_softmax`\n",
    "6. Beware of NaNs: Once a number becomes NaN it'll always be a NaN from then on\n",
    "    - Prevent underflow and overflow\n",
    "    - Remove missing values or replace them with finite values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4fe4f0",
   "metadata": {},
   "source": [
    "## Array Computing\n",
    "\n",
    "In machine learning and most of scientific computing we're not interested in operating on just single numbers at a time, but many numbers at a time. This is done using *array operations*. The most popular library in python for doing numerical computation on arrays is NumPy, or **numpy**. Why not just use python lists, you ask? A couple of reasons for this. For one, numpy comes with all sorts of useful numerical functions that operate on entire arrays. Perhaps more importantly, numpy compiles large array operations down to low-level C code, which executes much faster. This means doing operations in numpy can save you a *huge* amount of time.\n",
    "\n",
    "I'll start by importing numpy. We'll cover the important usages of each of these tools as we need them. Typically by convention, numpy is imported with the name `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e80da4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd932bcf",
   "metadata": {},
   "source": [
    "### Arrays and Types\n",
    "\n",
    "The fundamental object of numpy is the **array**. An array is very similar to a python list but supports all the numpy operations. To define an array, we can just define a python list and wrap it inside the function `np.array`. I'll create an array called `x` out of the list `[1, 2, 3, 4, 5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "903e407a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5]); x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6669d2",
   "metadata": {},
   "source": [
    "Just like python numbers, numpy arrays are typed. We can have an array of ints, an array of floats, an array of strings, etc. Not *all* objects can be put inside a numpy array though. Only immutable types like ints, floats, strings, or tuples. To get the type of the numbers in an array, call the method `dtype` on `x`. In the array I just defined, the type is `int64`, which is the numpy equivalent of the regular python `int`, which has 64 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa7c39d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a7e908",
   "metadata": {},
   "source": [
    "The other type of importance is of course the float, which is `float64` in numpy. We can specify the type either by passing floats into the array initially, or by recasting the array explicitly using the `astype` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbd729e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.astype('float64')\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9175baa1",
   "metadata": {},
   "source": [
    "Since arrays contain multiple values it's essential to know their **shape**. The shape of an array is the number of elements in each dimension of the array. To get the size of an array, use the `shape` method. It will return the number of values in each dimension of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b62908ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92faa9a4",
   "metadata": {},
   "source": [
    "The number of different dimensions an array has is called its **rank** or **order**. Equivalently, the rank is just the length of the shape tuple.\n",
    "\n",
    "The above array `x` is a rank-1 array with 5 elements. We can also define arrays with two, three, or any other number of dimensions we like. In math these arrays sometimes have special names depending on their dimension:\n",
    "- A rank-0 array is called a **scalar** (i.e. just a single number).\n",
    "- A rank-1 array is called a **vector**.\n",
    "- A rank-2 array is called a **matrix**.\n",
    "- A rank-3 or higher array is called a **tensor**.\n",
    "\n",
    "Here's an example of each. Next to each I print out their numpy shapes followed by the array itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c42db6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(1.5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = np.array(1.5)\n",
    "scalar.shape\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0e60fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = np.array([1, 2, 3])\n",
    "vector.shape\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5205e141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "matrix.shape\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65e7cff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "tensor.shape\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d1491",
   "metadata": {},
   "source": [
    "### Element-Wise Array Operations\n",
    "\n",
    "As you'd expect, we can also do arithmetic with arrays as well. Suppose for example we have two arrays like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a80b2070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3]); x\n",
    "y = np.array([4, 5, 6]); y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1b7c7c",
   "metadata": {},
   "source": [
    "We can efficiently operate on all numbers in these arrays by using **element-wise arithmetic**. The idea is to treat arrays like numbers. We can add, subtract, multiply, divide them. We can apply common functions like exponentials or logarithms. The difference for arrays is that these operations are applied on each number individually.\n",
    "\n",
    "For example, suppose we want to multiply `x` and `y` together. If we multiply each element index-by-index, or element-wise, we'd get something like this:\n",
    "```python\n",
    "x * y = [1 * 4, 2 * 5, 3 * 6] = [4, 10, 18].\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b520ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10, 18])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158efc5b",
   "metadata": {},
   "source": [
    "We can similarly do element-wise operations for addition, subtraction, multiplication by constants, exponentiation, even division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49451681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-3, -3, -3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([  1,  32, 729])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.4 , 0.5 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y\n",
    "x - y\n",
    "2 * x\n",
    "x ** y\n",
    "x / y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed565e44",
   "metadata": {},
   "source": [
    "We can also take element-wise sums, exponents, logs, sines, cosines, whatever we were doing with ints and floats before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9dc884a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.71828183,  7.3890561 , 20.08553692])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.69314718, 1.09861229])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.84147098, 0.90929743, 0.14112001])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.54030231, -0.41614684, -0.9899925 ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(x)\n",
    "np.log(x)\n",
    "np.sin(x)\n",
    "np.cos(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fe120f",
   "metadata": {},
   "source": [
    "Just like python lists, we can also sum the elements in an array using `np.sum`. If you just pass an array into `np.sum` with no other arguments, it will sum *every* element in the array, across all dimensions. If you only want to sum across a given dimension you need to pass in an `axis` argument specifying which dimension (i.e. axis) you want to sum over. Here's an example with a rank-2 array.\n",
    "\n",
    "To sum across every element, use `np.sum(A)`. To sum across all the rows, use `np.sum(A, axis=0)`. To sum across all the columns, use `np.sum(A, axis=1)`. Note these will necessarily change the output shape of `A`. \n",
    "\n",
    "Alternatively, you can use the method `A.sum()` in a similar way, which is sometimes more convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91ad4a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "A.shape\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6370369d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(A) # sum over all values in A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14af0e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 3,  7, 11])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_sums = A.sum(axis=1) # sum over all values in each row A\n",
    "row_sums.shape\n",
    "row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3676bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 9, 12])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_sums = A.sum(axis=0) # sum over all values in each column A\n",
    "col_sums.shape\n",
    "col_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15b682",
   "metadata": {},
   "source": [
    "Numpy also lets you calculate more aggregate operations over an array than just the sum. You can calculate the product of values in an array with `np.prod`, the cumulative sum with `np.cumsum`, the mean with `np.mean`, etc. We'll see examples of these as we go.\n",
    "\n",
    "Operations like this make it really convenient and efficient to perform operations on large arrays of data, which is very helpful in machine learning. We'll do it *a lot* going forward, without even thinking about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080a573",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "To finish this section I want to talk a little bit about the concept of broadcasting, which is essentially a set of conventions for doing array operations on arrays with improper shapes. This may seem like a strange thing to do, but it turns out knowing how and when to broadcast can make your code much shorter, more readable, and efficient. All major numerical array libraries in modern-day python support broadcasting, including numpy, pytorch, tensorflow, etc. So it's a useful thing to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f529f1",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "\n",
    "Let's start with a simple example. Suppose we have an array of floats `x = np.array([1., 2., 3., 4., 5.])`. We'd like to add 1 to every number in the array. How can we do it? One \"pythonic\" way might be to use a list comprehension like so. This will work just fine, but it requires going back and forth between arrays and lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee10bbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1., 2., 3., 4., 5.])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "608f60c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_plus_1 = np.array([val + 1 for val in x])\n",
    "x_plus_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6b2a1",
   "metadata": {},
   "source": [
    "What if we didn't want to go back and forth like that? It is slow after all. Anytime numpy has to handoff back to python or vice versa it's going to slow things down. Another thing we could try is to make a vector of ones of the same size as `x`, then add it to `x`. This is also fine, but it requires defining this extra array of ones just to add 1 to the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ca6c6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = np.ones(len(x))\n",
    "x_plus_1 = x + ones\n",
    "x_plus_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912707d",
   "metadata": {},
   "source": [
    "We'd *like* to be able to just add 1 to the array like we would with numbers. If `x` were a single number we'd just write `x + 1` to add one to it, right? But technically we can't do this if `x` is an array, since `x` has shape `(5,)` and 1 is just a number with no shape. This is where broadcasting comes in. Broadcasting says let's *define* the operation `x + 1` so that it *means* add 1 to every element of `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9d0b0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_plus_1 = x + 1\n",
    "x_plus_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9d39aa",
   "metadata": {},
   "source": [
    "This notation has the advantage of keeping array equations simple, while at the same time keeping all operations in numpy so that they run fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21010d2f",
   "metadata": {},
   "source": [
    "### Broadcasting Rules\n",
    "\n",
    "Suppose now that we have two arrays `A` and `B` of arbitrary shape and we want to operate on them, e.g. via the operations `+, -, *, /, //, **`. Here are the general broadcasting rules, quoted directly from the [numpy documentation](https://numpy.org/doc/stable/user/basics.broadcasting.html).\n",
    "\n",
    "> **Numpy Documentation**<br><br>When operating on two arrays, numpy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are **compatible** when <br><br>1. they are equal, or<br>2. one of them is 1 <br><br>If these conditions are not met, a `ValueError: operands could not be broadcast together` exception is thrown, indicating that the arrays have **incompatible** shapes. The size of the resulting array is the size that is not 1 along each axis of the inputs.\n",
    "\n",
    "Let's look at an example. First, suppose `A` has shape `(2, 2, 3)` and `B` has shape `(3,)`. Let's suppose for simplicity that they're both arrays of all ones. \n",
    "\n",
    "```\n",
    "A: 2 , 2 , 3\n",
    "B:         3\n",
    "------------\n",
    "C: 2 , 2 , 3\n",
    "```\n",
    "\n",
    "Here are the broadcasting steps that will take place. Note that only `B` will change in this example. `A` will stay fixed.\n",
    "- Numpy will start in the rightmost dimension, checking if they're equal.\n",
    "- Begin with `A` of shape `(2, 2, 3)` and `B` of shape `(3,)`.\n",
    "- In this case, the rightmost dimension is `3` in both arrays, so we have a match.\n",
    "- Moving left by one, `B` no longer has anymore dimensions, but `A` has two, each `2`. These arrays are thus compatible.\n",
    "- Numpy will now copy `B` to the left in these new dimensions until it has the same shape as `A`.\n",
    "\n",
    "```\n",
    "1. Copy values of B twice to get \n",
    "   B = [[1, 1, 1], [1, 1, 1]] \n",
    "   with shape (2, 3)\n",
    "2. Copy values of B twice to get \n",
    "   B = [[[1, 1, 1], [1, 1, 1]], [[1, 1, 1], [1, 1, 1]]] \n",
    "   with shape (2, 2, 3)\n",
    "```\n",
    "- The shapes of A and B are now equal. The output array `C` will have shape `(2, 2, 3)`.\n",
    "\n",
    "Let's verify this is true on two simple arrays of ones. Let's also print out what `C` looks like. Since only copying is taking place we should just be adding 2 arrays of ones, hence the output should sum 2 arrays of ones, giving one array `C` of twos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57c5d5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2, 3), (3,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.ones((2, 2, 3))\n",
    "B = np.ones(3,)\n",
    "A.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22608c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[2., 2., 2.],\n",
       "        [2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2.],\n",
       "        [2., 2., 2.]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = A + B\n",
    "C.shape\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126a712",
   "metadata": {},
   "source": [
    "Let's do one more example. Suppose now that `A` has shape `(8, 1, 6, 1)` and `B` has shape `(7, 1, 5)`.\n",
    "\n",
    "```\n",
    "A: 8 , 1 , 6 , 1\n",
    "B:     7 , 1 , 5\n",
    "----------------\n",
    "C: 8 , 7 , 6 , 5\n",
    "```\n",
    "\n",
    "Here are the broadcasting steps that will take place.\n",
    "- Starting again from the right, dimensions `1` and `5` don't match. But since `A` has a `1` rule (2) applies, so `A` will broadcast itself (i.e. copy its values) 5 times in this dimension to match `B`. \n",
    "- Moving left by one we get `6` and `1`. Now `B` will broadcast itself in this dimension 6 times to match `A`. \n",
    "- Moving left again we get `1` and `7`. Now `A` will broadcast itself in this dimension 7 times to match `B`. \n",
    "- Last, we get `8` in `A` and `B` is out of dimensions, so `B` will broadcast itself 8 times to match `A`. \n",
    "- The shapes of `A` and `B` are now equal. The output `C` thus has shape `(8, 7, 6, 5)`.\n",
    "\n",
    "Here again is an example on two arrays of ones. Verify that the shapes come out right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6175031e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 1, 6, 1), (7, 1, 5))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.ones((8, 1, 6, 1))\n",
    "B = np.ones((7, 1, 5))\n",
    "A.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50b23385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7, 6, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = A / B\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb84ac",
   "metadata": {},
   "source": [
    "That's pretty much all there is to broadcasting. It's a systematic way of trying to copy the dimensions in each array until they both have the same shape. All this broadcasting is done under the hood for you when you try to operate on two arrays of different shapes. You don't need to do anything but understand *how* the arrays get broadcast together so you can avoid errors in your calculations, sometimes very subtle errors.\n",
    "\n",
    "This can be a bit confusing to understand I'm sure. We'll practice broadcasting a good bit in future lessons to help you get the hang of it. Before long it should become second nature to you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
