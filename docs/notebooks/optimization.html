<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Math and Programming for Machine Learning - 10&nbsp; Optimization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notebooks/probability.html" rel="next">
<link href="../notebooks/multivariate-calculus.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Optimization</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Math and Programming for Machine Learning</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/programming.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Computer Programming</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/basic-math.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Basic Math</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/numerical-computing.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Numerical Computation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/calculus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Calculus</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/linear-systems.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Systems</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/vectors.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Vector Spaces</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/matrices.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Matrix Algebra</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/tensors.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Tensor Algebra</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/multivariate-calculus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Multivariate Calculus</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/optimization.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Optimization</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Basic Probability</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/multivariate-probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Multivariate Distributions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/statistics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Statistics</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#gradient-descent" id="toc-gradient-descent" class="nav-link active" data-scroll-target="#gradient-descent"><span class="toc-section-number">10.0.1</span>  Gradient Descent</a></li>
  </ul>
</nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Optimization</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<ul>
<li>Talk about what optimization is from a practical point of view</li>
<li>Define the univariate optimization problem, focusing mostly on the minimum of unconstrained cost functions</li>
<li>Derive Newton’s method from the version for root finding</li>
<li>Show how gradient descent is just Newton’s method when the Hessian is a scalar, the learning rate</li>
<li>Talk about higher-dimensional optimization, focusing first on convex functions and then talking about non-convex optimization via gradient descent to find a local stationary point (usually a saddlepoint)</li>
</ul>
<p>For the purposes of machine learning, by far the most important application of differentiation and calculus in general is to optimization. <strong>Optimization</strong> is the problem of finding the “best” values with respect to some function. Usually in machine learning, by “best” we mean finding the minimum value of a <em>loss function</em>, which is a function that measures agreement between a model’s prediction and the data it sees. Finding the minimum value of the loss function essentially means we’ve found the best weights for our model, the ones that give the highest accuracy on the data.</p>
<p>An interesting fact is that for a reasonably smooth function, its minimum value will <em>always</em> be at a point where the derivative is zero. To see why, consider our tangent line plot of <span class="math inline">\(y=x^2\)</span> from before. What happens if we set our point of interest to be <span class="math inline">\(x_0=0\)</span>? Clearly that’s the minimum of this function. At this point, the tangent line hugs the parabola horizontally, which means it’s a point where the slope is zero.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>dfdx <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">2</span> <span class="op">*</span> x</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>y0 <span class="op">=</span> f(x0)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>f_tangent = lambda x: y0 + dfdx(x0) * (x - x0) plot_function(x, (f, f_tangent), (-5, 5), (-2, 10), title=f’Tangent of <span class="math inline">\(y=x^2\)</span> at <span class="math inline">\({(x0,y0)}\)</span>’)</p>
<p>This same fact also holds for the maximum of a function as well. Not just the maximum, but any other point where the function is flat, called <strong>saddle points</strong>. As an example, the origin is a saddle-point of the function <span class="math inline">\(y=x^3\)</span>. These general points where the derivative is zero (min, max, or saddle point) are called <strong>stationary points</strong>.</p>
<p>In machine learning we usually care most about the minimum. I’ll just mention that we can formulate any maximum problem as a minimum problem by just multiplying the function by -1, which flips the function upside down, turning any maxima into minima.</p>
<p>Now, suppose we have a univariate function <span class="math inline">\(y=f(x)\)</span>. The problem of (unconstrained) optimization is to find a point <span class="math inline">\(x^*\)</span> such that <span class="math inline">\(y^* = f(x^*)\)</span> is the <strong>minimum</strong> value of <span class="math inline">\(f(x)\)</span>, i.e.&nbsp; <span class="math display">\[y^* = \min f(x) \leq f(x) \text{ for all } x.\]</span> The special point <span class="math inline">\(x^*\)</span> that minimizes the function is called the <strong>argmin</strong>, written <span class="math display">\[x^* = \text{argmin } f(x).\]</span></p>
<p>I need to mention a subtle point. What do I mean when I say “the minimum”? When I say <span class="math inline">\(y^* \leq f(x)\)</span> for all <span class="math inline">\(x\)</span>, which <span class="math inline">\(x\)</span> values am I talking about? This means we’re really only talking about the minimum over some <em>range</em> of <span class="math inline">\(x\)</span> values. We have to specify what that range is. If the range is the whole real line, it really is <em>the</em> minimum, usually called the <strong>global minimum</strong>. If it’s over some subset of the real line it may not be the global minimum since we’re not looking at every <span class="math inline">\(x\)</span>. It’s only the minimum in our region of interest. This sort of region-specific minimum is called a <strong>local minimum</strong>.</p>
<p>While this seems like a subtle point, it is an important one in machine learning. Some algorithms, like deep learning algorithms, can only reliably find a local minimum. Finding the global minimum can be harder unless there’s only one minimum to begin with. These simple functions are called <strong>convex functions</strong>. Our above example of <span class="math inline">\(y=x^2\)</span> is a convex function. It only has one minimum, and the function just slopes up around it on both sides in a bowl shape. Deep learning loss functions on the other hand are nasty, wiggly things with lots of bumps and valleys. Such functions are called <strong>non-convex functions</strong>. In general they’ll have lots of local minima.</p>
<p>So back to the fact about the derivative being zero at the minimum, what we “proved” by example is that at the point <span class="math inline">\(x^*\)</span> we should have <span class="math display">\[\frac{d}{dx}f(x^*)=0.\]</span> Another useful way to state the same fact is to think in terms of infinitesimals: At <span class="math inline">\(x^*\)</span>, any infinitesimal perturbation <span class="math inline">\(dx\)</span> won’t change the value of the function at all, <span class="math inline">\(f(x^*+dx) = f(x^*)\)</span>. This is just another way of stating that <span class="math inline">\(dy=0\)</span> at <span class="math inline">\(x^*\)</span>. The fact that small perturbations don’t change the function’s value is unique to minima and other stationary points.</p>
<p>Let’s verify this fact with the same example <span class="math inline">\(y=x^2\)</span> by looking at small perturbations around <span class="math inline">\(x=0\)</span>. Since <span class="math inline">\(f(0)=0\)</span> is a minimum, any perturbation should just give <span class="math inline">\(0\)</span> as well. Choosing a <span class="math inline">\(dx\)</span> of <code>1e-5</code>, we can see that the function’s perturbed value <span class="math inline">\(f(0+dx)\)</span> is only about <code>1e-10</code>, essentially negligible since <span class="math inline">\(dx^2 \approx 0\)</span> for infinitesimals. This won’t be true for any other value of <span class="math inline">\(x\)</span>, e.g.&nbsp;<span class="math inline">\(x=1\)</span>, which has a much larger change of <code>2e-5</code>, which is on the order of <span class="math inline">\(dx\)</span>, as expected.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>dx <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>f(<span class="dv">0</span> <span class="op">+</span> dx) <span class="op">-</span> f(<span class="dv">0</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>f(<span class="dv">1</span> <span class="op">+</span> dx) <span class="op">-</span> f(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Pretty much everything I’ve said on optimization extends naturally to higher dimensions. That’s why I went into so much detail on the simple univariate case. It’s easier to explain and visualize. To extend to <span class="math inline">\(n\)</span> dimensions we basically just need to convert inputs into vectors and derivatives into gradients. Other than this the formulas all look basically the same.</p>
<p>Suppose we have now a scalar-valued multivariate function <span class="math inline">\(z=f(\mathbf{x})=f(x_1,\cdots,x_n)\)</span>. The problem of (unconstrained) optimization is to find a vector <span class="math inline">\(\mathbf{x}^* \in \mathbb{R}^n\)</span> such that <span class="math inline">\(z^* = f(\mathbf{x}^*)\)</span> is the <strong>minimum</strong> value of <span class="math inline">\(f(\mathbf{x})\)</span>, i.e.&nbsp; <span class="math display">\[z^* = \min f(\mathbf{x}) \leq f(\mathbf{x}) \text{ for all } \mathbf{x} \in \mathbb{R}^n.\]</span> The vector <span class="math inline">\(\mathbf{x}^*\)</span> that minimizes the function is called the <strong>argmin</strong>, written <span class="math display">\[\mathbf{x}^* = \text{argmin } f(\mathbf{x}).\]</span></p>
<p>Just as the derivative is zero at the minimum in the univariate case, the <em>gradient</em> is the <em>zero vector</em> at the minimum in the multivariate case, <span class="math display">\[\frac{d}{d\mathbf{x}}f(\mathbf{x^*})=\mathbf{0}.\]</span> Another way of stating the same fact is that at the minimum <span class="math inline">\(f(\mathbf{x^*} + d\mathbf{x}) = f(\mathbf{x^*})\)</span> for any infinitesimal perturbation vector <span class="math inline">\(d\mathbf{x}\)</span>. Equivalently, <span class="math inline">\(dz=0\)</span>.</p>
<section id="gradient-descent" class="level3" data-number="10.0.1">
<h3 data-number="10.0.1" class="anchored" data-anchor-id="gradient-descent"><span class="header-section-number">10.0.1</span> Gradient Descent</h3>
<p>So if the minimum is so important how do we actually find the thing? For simple functions like <span class="math inline">\(y=x^2\)</span> we can do it just by plotting the function, or by trial and error. We can also do it analytically by solving the equation <span class="math inline">\(\frac{dy}{dx}\big|_{x^*}=0\)</span> for <span class="math inline">\(x^*\)</span>. But for complicated functions, or functions we can’t exactly write down, this isn’t feasible. We need an algorithmic way to do it.</p>
<p>Let’s try something simple. Since the derivative at <span class="math inline">\(x\)</span> tells us the slope of the function at <span class="math inline">\(x\)</span>, it’s in some sense telling us how far we are away from the minimum. Suppose we perturb <span class="math inline">\(x\)</span> to <span class="math inline">\(dx\)</span>. Then <span class="math inline">\(y=f(x)\)</span> gets perturbed to <span class="math inline">\(y+dy=f(x+dx)\)</span>. Now, observe the almost trivial fact that <span class="math display">\[dy = \frac{dy}{dx}dx.\]</span> So if <span class="math inline">\(\frac{dy}{dx}\)</span> is <em>large</em>, small changes in <span class="math inline">\(x\)</span> will result in large changes in <span class="math inline">\(y\)</span>. Similarly, if <span class="math inline">\(\frac{dy}{dx}\)</span> is <em>small</em>, then small changes in <span class="math inline">\(x\)</span> will result in small changes in <span class="math inline">\(y\)</span>. But we demonstrated above that if we’re near the minimum we <em>know</em> that changes in <span class="math inline">\(y\)</span> will be tiny if <span class="math inline">\(dx\)</span> is small. Thus, the derivative serves as a kind of “how close are we to the minimum” metric.</p>
<p>But that’s not all the derivative tells us. Since the sign of the derivative indicates which way the slope is slanting, it also tells us which direction the minimum is in. If you’re at a point on the function, the minimum will always be in the direction that’s sloping downward from you. Since the slope slants upward in the direction of the sign of the derivative, and we want to move downward the other way, <strong>the minimum will be in the direction of the negative of the derivative</strong>.</p>
<p>More formally, suppose we want to find the minimum of <span class="math inline">\(y=f(x)\)</span>. To start, we’ll pick a point <span class="math inline">\(x_0\)</span> at random. Doesn’t matter too much how. Pick a step size, we’ll call it <span class="math inline">\(\alpha\)</span>. This will multiply the derivative and tell us how big of a step to take towards the minimum (more on why this is important in a second). Now, we’ll take a step towards the minimum <span class="math display">\[x_1 = x_0 - \alpha \frac{dy}{dx}\bigg|_{x_0}.\]</span> This puts us at a new point <span class="math inline">\(x_1\)</span>, which will be closer to the argmin <span class="math inline">\(x^*\)</span> if our step size is small enough. Now do it again, <span class="math display">\[x_2 = x_1 - \alpha \frac{dy}{dx}\bigg|_{x_1}.\]</span> And again, <span class="math display">\[x_3 = x_2 - \alpha \frac{dy}{dx}\bigg|_{x_2}.\]</span> Keep doing this over and over. Stop when the points aren’t changing much anymore, i.e.&nbsp;when <span class="math inline">\(|x_{n+1}-x_n|&lt;\varepsilon\)</span> for some small tolerance <span class="math inline">\(\varepsilon\)</span>. Then we can say that the argmin is <span class="math inline">\(x^* \approx x_n\)</span>, and the minimum is <span class="math inline">\(y^* \approx f(x_n)\)</span>. Done.</p>
<p>This simple algorithm to find the (local) minimum by starting at a random point and steadily marching in the direction of the derivative is called <strong>gradient descent</strong>. With some relatively minor modifications here and there, gradient descent is how many machine learning algorithms are trained, including essentially all deep learning algorithms. It’s very possibly the most important algorithm in machine learning.</p>
<p>In machine learning, running an optimizer like gradient descent is usually called <strong>training</strong>. You can kind of imagine optimization as trying to teach something to a model. The condition of being at the minimum is analogous to the model learning whatever task it is you’re trying to teach it. The thing we’re minimizing in this case is the loss function, which is hand-picked essentially to measure how well the model is learning the given task.</p>
<p>The step size <span class="math inline">\(\alpha\)</span> is so important in machine learning that it’s given a special name, the <strong>learning rate</strong>. It in essence controls how quickly a model learns, or trains. I’ll use this terminology for <span class="math inline">\(\alpha\)</span> going forward.</p>
<p>Here’s what the algorithm looks like as a python function <code>gradient_descent</code>. It will take as arguments the function <code>f</code> we’re trying to minimize, the function for its derivative or gradient <code>grad_fn</code>, the initial point <code>x0</code>, the learning rate <code>alpha</code>. I’ll also pass in two optional arguments, <code>max_iter</code> and <code>eps</code>, where <code>max_iter</code> is how many iterations to run gradient descent in the worst case, and <code>eps</code> is the tolerance parameter to indicate when to stop.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descent(f, grad_fn, x0, alpha, max_iter<span class="op">=</span><span class="dv">1000</span>, eps<span class="op">=</span><span class="fl">1e-5</span>):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    x_prev <span class="op">=</span> x0  <span class="co"># initialize the algorithm</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_iter):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        x_curr <span class="op">=</span> x_prev <span class="op">-</span> alpha <span class="op">*</span> grad_fn(x_prev)  <span class="co"># gradient descent step</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.<span class="bu">abs</span>(x_curr <span class="op">-</span> x_prev) <span class="op">&lt;</span> eps:  <span class="co"># if changes are smaller than eps we're done, return x*</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'converged after </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> iterations'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> x_curr</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        x_prev <span class="op">=</span> x_curr</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'failed to converge in </span><span class="sc">{</span>max_iter<span class="sc">}</span><span class="ss"> iterations'</span>)  <span class="co"># else warn and return x* anyway</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x_curr</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s run this algorithm on our simple example <span class="math inline">\(y=x^2\)</span>. Recall its derivative function is <span class="math inline">\(\frac{dy}{dx}=2x\)</span>. I’ll choose an initial point <span class="math inline">\(x_0=5\)</span> and a learning rate of <span class="math inline">\(\alpha=0.8\)</span>. The optional arguments won’t change.</p>
<p>We can see that gradient descent in this case converges (i.e.&nbsp;finishes) after only 27 iterations. It predicts an argmin of about <span class="math inline">\(x^* \approx 3 \cdot 10^{-6}\)</span> and a minimum of about <span class="math inline">\(y^* \approx 9 \cdot 10^{12}\)</span>. Since both are basically <span class="math inline">\(0\)</span> (the true value for both) to within one part in <span class="math inline">\(10^{-5}\)</span> we seem to have done pretty well here.</p>
<p>Feel free to play around with different choices of the learning rate <code>alpha</code> to see how that affects training time and convergence. Getting a good feel for gradient descent is essential for a machine learning practitioner.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: x <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>grad_fn <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">2</span> <span class="op">*</span> x</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.8</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>x_min <span class="op">=</span> gradient_descent(f, grad_fn, x0, alpha)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>y_min <span class="op">=</span> f(x_min)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'estimated argmin: </span><span class="sc">{</span>x_min<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'estimated min: </span><span class="sc">{</span>y_min<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>While I’ve shown the math and code for gradient descent, we’ve still yet to get a good intuition for what the algorithm is doing. For this I’ll turn to a visualization. What I’m going to do is plot the function curve in black, and on top of it show each step of gradient descent. Each red dot on the curve of the function will indicate the point <span class="math inline">\((x_n,y_n)\)</span> at step <span class="math inline">\(n\)</span> of the algorithm. Successive steps will be connected by a red line. Each red line will show which points the algorithm jumps from and to at each step. Starting and ending points will be annotated as well.</p>
<p>To do this I’ll use a helper function <code>plot_gradient_descent</code>, which takes in the same arguments as <code>gradient_descent</code> as well as a few more arguments that do some styling of the plot. Internally, all this function is doing is running gradient descent on the given arguments, then plotting the functions, dots, and line segments described.</p>
<p>I’ll start by showing what gradient descent is doing on the exact same example as above. The curve of course is just a parabola sloping upward from the origin. The starting point is just <span class="math inline">\((x_0,f(x_0))=(5,25)\)</span>. After running for <span class="math inline">\(N=30\)</span> iterations the algorithm basically settles down to <span class="math inline">\((x_N,f(x_N)) \approx (0,0)\)</span>. Notice what’s happening in between though. Imagine you dropped a marble into a bowl at the starting point. After landing, the marble bounces across the bowl several times as it settles down around the origin, where it rolls around less and less until it eventually dissipates all its kinetic energy and settles down at the bottom of the bowl.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>plot_gradient_descent(f<span class="op">=</span>f, grad_fn<span class="op">=</span>grad_fn, x0<span class="op">=</span>x0, alpha<span class="op">=</span>alpha, n_iters<span class="op">=</span><span class="dv">30</span>, </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>                      title<span class="op">=</span><span class="ss">f'$y=x^2$,  $</span><span class="ch">\\</span><span class="ss">alpha=</span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">$,  $N=</span><span class="sc">{</span><span class="dv">30</span><span class="sc">}</span><span class="ss">$,  $x_0=</span><span class="sc">{</span>x0<span class="sc">}</span><span class="ss">$'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To illustrate what the learning rate is doing, and how important it is to tune it well, let’s try the same problem in two other cases: a really high learning rate, and a really low learning rate. I’ll start with a high learning rate of <span class="math inline">\(\alpha=1.1\)</span>. I’ll run the algorithm this time for <span class="math inline">\(N=20\)</span> iterations.</p>
<p>Pay particular attention in this case to the start and end labels. Evidently choosing a high learning rate caused the algorithm not to spiral down towards the minimum, but to spiral up away from the minimum! This is the hallmark of choosing too large a learning rate. The algorithm won’t converge at all. It’ll just keep shooting further and further away from the minimum.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">1.1</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>plot_gradient_descent(f<span class="op">=</span>f, grad_fn<span class="op">=</span>grad_fn, x0<span class="op">=</span>x0, alpha<span class="op">=</span>alpha, n_iters<span class="op">=</span><span class="dv">10</span>, </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>                      title<span class="op">=</span><span class="ss">f'$y=x^2$,  $</span><span class="ch">\\</span><span class="ss">alpha=</span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">$,  $N=</span><span class="sc">{</span><span class="dv">30</span><span class="sc">}</span><span class="ss">$,  $x_0=</span><span class="sc">{</span>x0<span class="sc">}</span><span class="ss">$'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Let’s now look at a low learning rate of <span class="math inline">\(\alpha=0.01\)</span>. I’ll run this one for <span class="math inline">\(N=150\)</span> iterations. Notice now that the algorithm is indeed converging towards the minimum, but it’s doing it really, really slowly. It’s not bouncing around the bowl at all, but rather slowly crawling down in small steps. This is the hallmark of using too low a learning rate. The algorithm will converge, but it’ll do so really, really slowly, and you’ll need to train for a lot of iterations.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">0.01</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plot_gradient_descent(f<span class="op">=</span>f, grad_fn<span class="op">=</span>grad_fn, x0<span class="op">=</span>x0, alpha<span class="op">=</span>alpha, n_iters<span class="op">=</span>N,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                      title<span class="op">=</span><span class="ss">f'$y=x^2$,  $</span><span class="ch">\\</span><span class="ss">alpha=</span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">$,  $N=</span><span class="sc">{</span>N<span class="sc">}</span><span class="ss">$,  $x_0=</span><span class="sc">{</span>x0<span class="sc">}</span><span class="ss">$'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Things may seem all fine and good. We have an algorithm that seems like it can reliably find the minimum of whatever function we give it, at least in the univariate case. Unfortunately, there are a few subtleties involved that I’ve yet to mention. It turns out that the function I picked, <span class="math inline">\(y=x^2\)</span> is a particularly easy function to minimize. It’s a convex function. Not all functions behave that nicely. Practically no loss function in deep learning does.</p>
<p>If a function is non-convex (i.e.&nbsp;not bowl-shaped) it can have multiple minima. This means that you can’t be sure gradient descent will pick out the global minimum if you run it. Which minimum it settles in will depend on your choice of initial point <span class="math inline">\(x_0\)</span>, the learning rate <span class="math inline">\(\alpha\)</span>, and perhaps even the number of iterations <span class="math inline">\(N\)</span> you run the algorithm.</p>
<p>This isn’t the only problem, or even the worst problem. Perhaps the worst problem is saddle points. If there are saddle points in the function, gradient descent may well settle down on one of those instead of any of the minima. Here’s an example of this. Let’s look at the function <span class="math inline">\(y=x^3 + (x+1)^4\)</span>. Its derivative function turns out to be <span class="math inline">\(\frac{dy}{dx}=3x^2 + 4(x+1)^3\)</span>. Check WolframAlpha if you don’t believe me.</p>
<p>Now, suppose we want to find the minimum of this function. Not knowing any better, we pick an initial point <span class="math inline">\(x_0=3\)</span>, and just to be safe we pick a small learning rate <span class="math inline">\(\alpha=0.001\)</span>. Let’s run gradient descent now for <span class="math inline">\(N=500\)</span> iterations. Surely that’s enough to find the minimum, right?</p>
<p>Evidently not. The true minimum seems to be somewhere around the point <span class="math inline">\((-2.8, -12)\)</span>. The algorithm didn’t settle down anywhere near this point. It settled around the origin <span class="math inline">\((0,0)\)</span>. So what happened? If you look closely, you’ll see it got stuck in a flat spot, i.e.&nbsp;a saddle point. No matter how many iterations you run gradient descent with this learning rate, it will never leave this flat spot. It’s stuck.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: x <span class="op">**</span> <span class="dv">3</span> <span class="op">+</span> (x <span class="op">+</span> <span class="dv">1</span>) <span class="op">**</span> <span class="dv">4</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>grad_fn <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">3</span> <span class="op">*</span> x <span class="op">**</span> <span class="dv">2</span> <span class="op">+</span> <span class="dv">4</span> <span class="op">*</span> (x <span class="op">+</span> <span class="dv">1</span>) <span class="op">**</span> <span class="dv">3</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>alpha<span class="op">=</span><span class="fl">0.001</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>plot_gradient_descent(f, grad_fn, x0, alpha<span class="op">=</span>alpha, n_iters<span class="op">=</span>N, xlim<span class="op">=</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">2</span>), ylim<span class="op">=</span>(<span class="op">-</span><span class="dv">15</span>, <span class="dv">50</span>), </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                      title<span class="op">=</span><span class="ss">f'$y=x^3 + (x-1)^4$,  $</span><span class="ch">\\</span><span class="ss">alpha=</span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">$,  $N=</span><span class="sc">{</span>N<span class="sc">}</span><span class="ss">$,  $x_0=</span><span class="sc">{</span>x0<span class="sc">}</span><span class="ss">$'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>All isn’t necessarily lost. What happens if we pick a higher learning rate to let the algorithm bounce around the function a little bit before slowing down? Let’s pick <span class="math inline">\(\alpha=0.03\)</span> now and run for the same number of iterations. Now it looks like we’re doing just fine. Gradient descent was able to bounce across the flat spot and settle down at the other side.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>alpha<span class="op">=</span><span class="fl">0.03</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>plot_gradient_descent(f, grad_fn, x0, alpha<span class="op">=</span>alpha, n_iters<span class="op">=</span>N, xlim<span class="op">=</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">4</span>), ylim<span class="op">=</span>(<span class="op">-</span><span class="dv">15</span>, f(<span class="dv">3</span>) <span class="op">+</span> <span class="dv">20</span>), </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>                      annotate_start_end<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>                      title<span class="op">=</span><span class="ss">f'$y=x^3 + (x-1)^4$,  $</span><span class="ch">\\</span><span class="ss">alpha=</span><span class="sc">{</span>alpha<span class="sc">}</span><span class="ss">$,  $N=</span><span class="sc">{</span>N<span class="sc">}</span><span class="ss">$,  $x_0=</span><span class="sc">{</span>x0<span class="sc">}</span><span class="ss">$'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This example was meant to show that saddle points can be a real issue. Gradient descent will not tell you if the point it found is a minimum or a saddle point, it’ll just stop running and spit out a value. You thus need to be careful about things like this when running gradient descent on real-life functions. It’s even worse in higher dimensions, where it turns out that almost all stationary points will be saddle points, and very few will be minima or maxima.</p>
<p>For these reasons, it’s common in machine learning to not use a tolerance condition like <span class="math inline">\(|x_{n}-x_{n-1}| &lt; \varepsilon\)</span>. Instead we just specify some number of iterations <span class="math inline">\(N\)</span> and run the algorithm <span class="math inline">\(N\)</span> times. Basically, we want to give the algorithm a chance to get out of a flat spot if it gets stuck in one for some reason. Said differently, if a function is not convex, and most in machine learning are not convex, the notion of convergence doesn’t necessarily mean that much since we don’t even know if we’re at a minimum or not.</p>
<p>The gradient descent algorithm works exactly the same as in the univariate case, except we now use the gradient vector instead of the derivative at each step. Here’s the algorithm in steps: 1. Initialize a starting vector <span class="math inline">\(\mathbf{x}_0\)</span>. 2. For <span class="math inline">\(N\)</span> iterations, perform the gradient descent update <span class="math display">\[\mathbf{x}_n = \mathbf{x}_{n-1} - \alpha \frac{dz}{d\mathbf{x}}\bigg|_{\mathbf{x}=\mathbf{x}_{n-1}}.\]</span> 3. Converge either when some convergence criterion is satisfied, <span class="math inline">\(||\mathbf{x}_n-\mathbf{x}_{n-1}||_2 \leq \varepsilon\)</span>, or when some maximum number of iterations <span class="math inline">\(N\)</span> is reached. 4. Return <span class="math inline">\(\mathbf{x}_N\)</span>. The best guess for the argmin is <span class="math inline">\(\mathbf{x}^* \approx \mathbf{x}_N\)</span>, and for the minimum is <span class="math inline">\(z^* \approx f(\mathbf{x}_N)\)</span>.</p>
<p><strong>Aside:</strong> I’ll quickly note that gradient descent isn’t the only minimization algorithm. Some other algorithms worth noting use not just the first derivative in their updates, but also the second derivative. Examples include algorithms like Newton’s Method and LBFGS. The second derivative provides information about the curvature of the function, which can speed up convergence by making the learning rate adaptive. While these <em>second-order</em> algorithms are useful in some areas of machine learning, it usually turns out to be far too computationally expensive to calculate the second derivative (also called the Hessian) of a function in high dimensions. Perhaps the main reason gradient descent is used in machine learning is because it provides a good tradeoff between its speed of convergence and computational performance.</p>
<p>This pretty much covers everything I wanted to talk about regarding optimization, the most important application of calculus to machine learning. In future lessons we’ll spend more time talking about gradient descent as well as its more modern variants like SGD and Adam.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-page-right">
  <div class="nav-page nav-page-previous">
      <a href="../notebooks/multivariate-calculus.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Multivariate Calculus</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notebooks/probability.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Basic Probability</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>