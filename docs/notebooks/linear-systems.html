<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Mathematics and Computer Science for Machine Learning - 5&nbsp; Linear Systems</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notebooks/vectors.html" rel="next">
<link href="../notebooks/calculus.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Systems</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Mathematics and Computer Science for Machine Learning</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/algorithms.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Programming and Algorithms</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/basic-math.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Basic Math</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/numerical-computing.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Numerical Computation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/calculus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Calculus</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/linear-systems.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Systems</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/vectors.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Vector Spaces</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/matrices.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Matrix Algebra</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/tensors.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Tensor Algebra</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/multivariate-calculus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Multivariate Calculus</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/optimization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Optimization</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Basic Probability</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/multivariate-probability.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Multivariate Distributions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/statistics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Math for ML: Statistics</span></a>
  </div>
</li>
    </ul>
    </div>
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#linear-functions" id="toc-linear-functions" class="nav-link active" data-scroll-target="#linear-functions"><span class="toc-section-number">5.1</span>  Linear Functions</a></li>
  <li><a href="#matrix-vector-notation" id="toc-matrix-vector-notation" class="nav-link" data-scroll-target="#matrix-vector-notation"><span class="toc-section-number">5.2</span>  Matrix-Vector Notation</a></li>
  <li><a href="#matrix-multiplication" id="toc-matrix-multiplication" class="nav-link" data-scroll-target="#matrix-multiplication"><span class="toc-section-number">5.3</span>  Matrix Multiplication</a>
  <ul class="collapse">
  <li><a href="#matrix-multiplication-algorithm" id="toc-matrix-multiplication-algorithm" class="nav-link" data-scroll-target="#matrix-multiplication-algorithm"><span class="toc-section-number">5.3.1</span>  Matrix Multiplication Algorithm</a></li>
  <li><a href="#chained-matrix-multiplication" id="toc-chained-matrix-multiplication" class="nav-link" data-scroll-target="#chained-matrix-multiplication"><span class="toc-section-number">5.3.2</span>  Chained Matrix Multiplication</a></li>
  <li><a href="#matrix-multiplication-vs-element-wise-multiplication" id="toc-matrix-multiplication-vs-element-wise-multiplication" class="nav-link" data-scroll-target="#matrix-multiplication-vs-element-wise-multiplication"><span class="toc-section-number">5.3.3</span>  Matrix Multiplication vs Element-Wise Multiplication</a></li>
  <li><a href="#interpreting-matrix-multiplication" id="toc-interpreting-matrix-multiplication" class="nav-link" data-scroll-target="#interpreting-matrix-multiplication"><span class="toc-section-number">5.3.4</span>  Interpreting Matrix Multiplication</a></li>
  </ul></li>
  <li><a href="#solving-linear-systems" id="toc-solving-linear-systems" class="nav-link" data-scroll-target="#solving-linear-systems"><span class="toc-section-number">5.4</span>  Solving Linear Systems</a>
  <ul class="collapse">
  <li><a href="#square-linear-systems" id="toc-square-linear-systems" class="nav-link" data-scroll-target="#square-linear-systems"><span class="toc-section-number">5.4.1</span>  Square Linear Systems</a></li>
  <li><a href="#rectangular-systems" id="toc-rectangular-systems" class="nav-link" data-scroll-target="#rectangular-systems"><span class="toc-section-number">5.4.2</span>  Rectangular Systems</a></li>
  </ul></li>
  </ul>
</nav>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Systems</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>In this lesson I’ll introduce the basics of linear algebra by talking about linear systems of equations and the matrix-vector notation. Let’s get started.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sympy <span class="im">as</span> sp</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> utils.math_ml <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="linear-functions" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="linear-functions"><span class="header-section-number">5.1</span> Linear Functions</h2>
<p>We’ve already seen scalar linear functions, which have the form <span class="math inline">\(y = ax\)</span>. Linear functions, like the name suggests, represent lines in the plane. Since <span class="math inline">\(y=0\)</span> if <span class="math inline">\(x=0\)</span>, those lines must always pass through the origin.</p>
<p>The coefficient <span class="math inline">\(a\)</span> is called the <strong>slope</strong> of the function. It determines the steepness of the line and whether the line slants to the left or to the right. The slope also represents the derivative of the function, since</p>
<p><span class="math display">\[\frac{dy}{dx} = a.\]</span></p>
<p>The fact that the derivative is the slope tells us something about what <span class="math inline">\(a\)</span> means practically speaking. It’s the amount that <span class="math inline">\(y\)</span> changes in response to changes in <span class="math inline">\(x\)</span>. If we increase <span class="math inline">\(x\)</span> by one unit, then <span class="math inline">\(y\)</span> changes by <span class="math inline">\(a\)</span> units. In this sense, you can also think of <span class="math inline">\(a\)</span> as a <em>weight</em> or a <em>gain</em> that tells how much <span class="math inline">\(x\)</span> influences <span class="math inline">\(y\)</span>.</p>
<p>For example, suppose you’re on a road trip, say from San Francisco to Los Angeles. You look at your speedometer and reason that you’re averaging a speed of about <span class="math inline">\(a=60\)</span> miles per hour. If you’ve already driven for <span class="math inline">\(x=5\)</span> hours and covered a distance of <span class="math inline">\(y=300\)</span> miles, how much more distance will you cover if you drive for <span class="math inline">\(dx=1\)</span> more hour? Clearly it’s <span class="math inline">\(a=60\)</span> miles, which will bring your distance traveled to <span class="math inline">\(y+dy=360\)</span> miles. That’s all the slope is saying.</p>
<p>The above example corresponds to the linear equation <span class="math inline">\(y=60x\)</span>. Here’s a plot of what this looks like. Nothing special, just a line with slope <span class="math inline">\(60\)</span>.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="dv">60</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x: a <span class="op">*</span> x</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>plot_function(x, f, xlim<span class="op">=</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>), ylim<span class="op">=</span>(<span class="op">-</span><span class="dv">100</span>, <span class="dv">100</span>), title<span class="op">=</span><span class="ss">f'$y=</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss">x$'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="linear-systems_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>If there are two inputs <span class="math inline">\(x_0\)</span> and <span class="math inline">\(x_1\)</span>, a linear function would look like</p>
<p><span class="math display">\[y = a_0 x_0 + a_1 x_1.\]</span></p>
<p>This defines a <em>plane</em> in 3-dimensional space that passes through the origin. Each coefficient again tells you something about how the output changes if that input is changed. If <span class="math inline">\(x_0\)</span> is changed by one unit, holding <span class="math inline">\(x_1\)</span> fixed, then <span class="math inline">\(y\)</span> changes by <span class="math inline">\(a_0\)</span> units. Similarly, if <span class="math inline">\(x_1\)</span> is changed by one unit, holding <span class="math inline">\(x_0\)</span> fixed, then <span class="math inline">\(y\)</span> changes by <span class="math inline">\(a_1\)</span> units.</p>
<p>Here’s an example. Take <span class="math inline">\(y = 5x_0 - 2x_1\)</span>. It will look like the plane shown below. Changing <span class="math inline">\(x_0\)</span> by one unit while holding <span class="math inline">\(x_1\)</span> fixed will cause <span class="math inline">\(y\)</span> to <em>increase</em> by <span class="math inline">\(5\)</span> units. Changing <span class="math inline">\(x_1\)</span> by one unit while holding <span class="math inline">\(x_0\)</span> fixed will cause <span class="math inline">\(y\)</span> to <em>decrease</em> by <span class="math inline">\(2\)</span> units.</p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>a0, a1 <span class="op">=</span> <span class="dv">5</span>, <span class="op">-</span><span class="dv">2</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>x0 <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="kw">lambda</span> x0, x1: a0 <span class="op">*</span> x0 <span class="op">+</span> a1 <span class="op">*</span> x1</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>plot_function_3d(x0, x1, f, azim<span class="op">=</span><span class="dv">80</span>, elev<span class="op">=</span><span class="dv">25</span>, ticks_every<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">10</span>],</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>                 titlepad<span class="op">=</span><span class="dv">6</span>, labelpad<span class="op">=</span><span class="dv">3</span>, title<span class="op">=</span><span class="ss">f'$y=5x_0 - 2x_1$'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="linear-systems_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This idea readily extends to <span class="math inline">\(n\)</span> variables too, though you can’t visualize it anymore. If there are <span class="math inline">\(n\)</span> variables <span class="math inline">\(x_0, x_1, \cdots, x_{n-1}\)</span>, a linear function has the form</p>
<p><span class="math display">\[y = a_0 x_0 + a_1 x_1 + \cdots a_{n-1} x_{n-1}.\]</span></p>
<p>This equation now defines a <em>hyperplane</em> in <span class="math inline">\(n\)</span>-dimensional space that passes through the origin. Each coefficient <span class="math inline">\(a_i\)</span> represents how much <span class="math inline">\(y\)</span> changes if <span class="math inline">\(x_i\)</span> is increased by one unit, while holding all the other <span class="math inline">\(x_j\)</span> fixed.</p>
<p>We can also think about <em>systems</em> of linear equations. For example, we can have 2 outputs <span class="math inline">\(y_0, y_1\)</span>, each of which is its own linear function of 3 input variables <span class="math inline">\(x_0, x_1, x_2\)</span>. It might look like this</p>
<p><span class="math display">\[\begin{alignat*}{5}
y_0 &amp; {}={}   a_{0,0} x_0 &amp; {}+{} &amp;  a_{0,1} x_1 &amp; {}+{} &amp; a_{0,2} x_2 \\
y_1 &amp; {}={}   a_{1,0} x_0 &amp; {}+{} &amp;  a_{1,1} x_1 &amp; {}+{} &amp; a_{1,2} x_2. \\
\end{alignat*}\]</span></p>
<p>The most general situation we’ll consider is a system of <span class="math inline">\(m\)</span> linear equations with <span class="math inline">\(n\)</span> inputs,</p>
<p><span class="math display">\[
\begin{array}{c&lt;{x_0} c c&lt;{x_1} c c&lt;{\cdots} c c&lt;{x_{n-1}} c l}
y_0 &amp; = &amp; a_{0,0}x_0 &amp; + &amp; a_{0,1}x_1 &amp; + &amp; \cdots &amp; + &amp; a_{0,n-1}x_{n-1} \\
y_1 &amp; = &amp; a_{1,0}x_0 &amp; + &amp; a_{1,1}x_1 &amp; + &amp; \cdots &amp; + &amp; a_{1,n-1}x_{n-1} \\
\vdots &amp; &amp; \vdots    &amp;   &amp; \vdots    &amp;   &amp;  \ddots  &amp;   &amp; \quad \vdots\\
y_{m-1} &amp; = &amp; a_{m-1,0}x_0 &amp; + &amp; a_{m-1,1}x_1 &amp; + &amp; \cdots &amp; + &amp; a_{m-1,n-1}x_{n-1}. \\
\end{array}
\]</span></p>
<p>This kind of linear system is often called an <span class="math inline">\(m \times n\)</span> linear system, or a system of <span class="math inline">\(m\)</span> linear equations with <span class="math inline">\(n\)</span> unknowns. There are <span class="math inline">\(m \cdot n\)</span> coefficients in this system, namely <span class="math inline">\(a_{0,0}, \cdots, a_{m-1,n-1}\)</span>. Each <span class="math inline">\(a_{i,j}\)</span> would tell you how much the output <span class="math inline">\(y_i\)</span> would change if the input <span class="math inline">\(x_j\)</span> was increased by one unit. Visually, you can think of an <span class="math inline">\(m \times n\)</span> linear system as corresponding to a set of <span class="math inline">\(m\)</span> <span class="math inline">\(n\)</span>-dimensional hyperplanes.</p>
</section>
<section id="matrix-vector-notation" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="matrix-vector-notation"><span class="header-section-number">5.2</span> Matrix-Vector Notation</h2>
<p>Linear systems of equations are incredibly cumbersome to work with in all but the simplest cases of like 2 or 3 equations. There’s a much cleaner notation for working with these linear systems. Here’s what we can do. Notice we seem to have three separate types of objects showing up in these equations:</p>
<ul>
<li>The <span class="math inline">\(m\)</span> output variables <span class="math inline">\(y_0, y_1, \cdots, y_{m-1}\)</span>.</li>
<li>The <span class="math inline">\(m \cdot n\)</span> coefficients <span class="math inline">\(a_{0,0}, \ a_{0,1}, \ \cdots, \ a_{m-1,n-1}\)</span>.</li>
<li>The <span class="math inline">\(n\)</span> input variables <span class="math inline">\(x_0, x_1, \cdots, x_{n-1}\)</span>.</li>
</ul>
<p>Let’s put each of these sets into their own array, and <em>define</em> an <span class="math inline">\(m \times n\)</span> linear system of equations to mean the same thing as the following expression,</p>
<p><span class="math display">\[
\begin{pmatrix}
y_0 \\ y_1 \\ \vdots \\ y_{m-1}
\end{pmatrix} =
\begin{pmatrix}
a_{0,0} &amp; a_{0,1} &amp; \cdots &amp; a_{0,n-1} \\
a_{1,0} &amp; a_{1,1} &amp; \cdots &amp; a_{1,n-1} \\
\vdots  &amp; \vdots  &amp; \ddots &amp; \vdots    \\
a_{m-1,0} &amp; a_{m-1,1} &amp; \cdots &amp; a_{m-1,n-1}
\end{pmatrix}
\begin{pmatrix}
x_0 \\ x_1 \\ \vdots \\ x_{n-1}
\end{pmatrix}.
\]</span></p>
<p>Each of these arrays is a 2-dimensional array. The left-most array is a shape <span class="math inline">\((m, 1)\)</span> array of outputs, and the right-most array is a shape <span class="math inline">\((n, 1)\)</span> array of inputs. These are both called <strong>column vectors</strong>, or when we’re being sufficiently lazy just <strong>vectors</strong>. Even though they’re not <em>technically</em> 1-dimensional arrays, and hence not technically vectors, they’re close enough that they might as well be. They’re <em>isomorphic</em> to vectors. The middle array is a shape <span class="math inline">\((m, n)\)</span> array of coefficients. We’ll call this array an <span class="math inline">\(m \times n\)</span> <strong>matrix</strong>.</p>
<p>Here’s a couple of examples of going back and forth between equation notation and matrix-vector notation so you get the idea. It’s good to be able to do this kind of thing without thinking. I’ll frequently go back and forth from now on depending on which notation is most convenient.</p>
<p><span class="math display">\[\begin{gather*}
\begin{alignedat}{3}
   y_0 &amp; {}={} &amp; 3x_0 &amp; {}+{} &amp;  x_1  \\
   y_1 &amp; {}={} &amp; x_0 &amp; {}-{} &amp;  2x_1
\end{alignedat}
\quad \Longleftrightarrow \quad
\begin{pmatrix}
y_0 \\
y_1
\end{pmatrix} =
\begin{pmatrix}
3 &amp; 1 \\
1 &amp; -2
\end{pmatrix}
\begin{pmatrix}
x_0 \\
x_1
\end{pmatrix},
\end{gather*}\]</span></p>
<p><span class="math display">\[\begin{gather*}
\begin{alignedat}{5}
   y_0 &amp; {}={} &amp; x_0 &amp; {}+{} &amp;  2x_1 &amp; {}+{} &amp; 3x_2  \\
   y_1 &amp; {}={} &amp; 4x_0 &amp; {}-{} &amp;  5x_1 &amp; {} {} &amp;
\end{alignedat}
\quad \Longleftrightarrow \quad
\begin{pmatrix}
y_0 \\
y_1 \\
\end{pmatrix} =
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 0
\end{pmatrix}
\begin{pmatrix}
x_0 \\
x_1 \\
x_2
\end{pmatrix}.
\end{gather*}\]</span></p>
<p>It’s convenient to use an abstract notation to express vectors and matrices so we can more easily manipulate them. If we define the symbol <span class="math inline">\(\mathbf{x}\)</span> to represent the column vector of inputs, the symbol <span class="math inline">\(\mathbf{y}\)</span> to represent the column vector of outputs, and the symbol <span class="math inline">\(\mathbf{A}\)</span> to represent the matrix of coefficients, we can write the same <span class="math inline">\(m \times n\)</span> linear system in the much simpler form</p>
<p><span class="math display">\[\mathbf{y} = \mathbf{A} \mathbf{x}.\]</span></p>
<p>This looks almost just like the simple one-dimensional linear equation <span class="math inline">\(y=ax\)</span>, except it’s packing a lot more into it that we’ll have to analyze. By convention, I’ll use bold-face characters to represent vectors and matrices (and tensors) in this book. For this most part, I’ll try to use lower-case letters for vectors, and upper-case letters for matrices. This is an almost universally followed convention, but it’s not unanimous.</p>
<p>To index into these arrays, I’ll mostly use subscript notation. For example, the element of <span class="math inline">\(\mathbf{x}\)</span> at index <span class="math inline">\(i\)</span> will be denoted <span class="math inline">\(x_i\)</span>. The element of <span class="math inline">\(\mathbf{A}\)</span> at index <span class="math inline">\((i,j)\)</span> will be denoted <span class="math inline">\(A_{i,j}\)</span>. Sometimes I’ll also use the code equivalent of <span class="math inline">\(x[i]\)</span> or <span class="math inline">\(A[i,j]\)</span> when it’s more clear. Following the python convention, I’ll always index starting from <span class="math inline">\(0\)</span>, so that an array of <span class="math inline">\(n\)</span> elements goes from <span class="math inline">\(0, 1, \cdots, n-1\)</span>, <em>not</em> from <span class="math inline">\(1, 2, \cdots, n\)</span> as is more typical in math books. I do this mainly to make going between math and code easier, as index errors can be a pain to deal with.</p>
<p>It may not be at all obvious, but having written a linear system as a matrix-vector equation, I’ve implicitly defined a new kind of array multiplication. To see this, I’ll define a new column vector that I’ll call <span class="math inline">\(\mathbf{A} \mathbf{x}\)</span> whose elements are just the right-hand side of the linear system when written out,</p>
<p><span class="math display">\[
\mathbf{A} \mathbf{x} =
\begin{pmatrix}
a_{0,0}x_0 &amp; + &amp; a_{0,1}x_1 &amp; + &amp; \cdots &amp; + &amp; a_{0,n-1}x_{n-1} \\
a_{1,0}x_0 &amp; + &amp; a_{1,1}x_1 &amp; + &amp; \cdots &amp; + &amp; a_{1,n-1}x_{n-1} \\
\vdots    &amp;   &amp; \vdots    &amp;   &amp;  \ddots  &amp;   &amp; \quad \vdots     \\
a_{m-1,0}x_0 &amp; + &amp; a_{m-1,1}x_1 &amp; + &amp; \cdots &amp; + &amp; a_{m-1,n-1}x_{n-1} \\
\end{pmatrix}.
\]</span></p>
<p>Setting the <span class="math inline">\(i\)</span><sup>th</sup> row of <span class="math inline">\(\mathbf{A} \mathbf{x}\)</span> equal to the <span class="math inline">\(i\)</span><sup>th</sup> row of <span class="math inline">\(\mathbf{y}\)</span> must imply that each element <span class="math inline">\(y_i\)</span> can be written</p>
<p><span class="math display">\[y_i = a_{i,0}x_0 + a_{i,1}x_1 + \cdots + a_{i,n-1}x_{n-1} = \sum_{k=0}^{n-1} a_{i,k}x_k.\]</span></p>
<p>That is, each constant term <span class="math inline">\(y_i\)</span> is the sum of the products of the <span class="math inline">\(i\)</span><sup>th</sup> row of the matrix <span class="math inline">\(\mathbf{A}\)</span> with the vector <span class="math inline">\(\mathbf{x}\)</span>. This is <strong>matrix-vector multiplication</strong>, a special case of matrix multiplication, which I’ll get to shortly. Note that this operation is only defined when the number columns of <span class="math inline">\(\mathbf{A}\)</span> matches the size of <span class="math inline">\(\mathbf{x}\)</span>. We say in this case that <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{x}\)</span> are <strong>compatible</strong>.</p>
<p>Here’s a quick example, where a <span class="math inline">\(2 \times 3\)</span> matrix <span class="math inline">\(\mathbf{A}\)</span> is matrix multiplied with a size <span class="math inline">\(3\)</span> vector <span class="math inline">\(\mathbf{x}\)</span>. For each row we’re element-wise multiplying that row of <span class="math inline">\(\mathbf{A}\)</span> with the vector <span class="math inline">\(\mathbf{x}\)</span> and then summing up the terms. The output will be the vector <span class="math inline">\(\mathbf{y}\)</span> of size <span class="math inline">\(2\)</span>.</p>
<p><span class="math display">\[
\mathbf{A} \mathbf{x} =
\begin{pmatrix}
\color{red}{1} &amp; \color{red}{2} &amp; \color{red}{3} \\
\color{blue}{4} &amp; \color{blue}{5} &amp; \color{blue}{6}
\end{pmatrix}
\begin{pmatrix}
1 \\
1 \\
1
\end{pmatrix} =
\begin{pmatrix}
\color{red}{1} \color{black}{\cdot} \color{black}{1} \color{black}{+} \color{red}{2} \color{black}{\cdot} \color{black}{1} \color{black}{+} \color{red}{3} \color{black}{\cdot} \color{black}{1} \\
\color{blue}{4} \color{black}{\cdot} \color{black}{1} \color{black}{+} \color{blue}{5} \color{black}{\cdot} \color{black}{1} \color{black}{+} \color{blue}{6} \color{black}{\cdot} \color{black}{1} \\
\end{pmatrix} =
\begin{pmatrix}
6 \\
15
\end{pmatrix} = \mathbf{y}.
\]</span></p>
<p>I used the color coding to help illustrate a point. Notice that each element of <span class="math inline">\(\mathbf{y}\)</span> is just that row of <span class="math inline">\(\mathbf{A}\)</span> being element-wise multiplied by <span class="math inline">\(\mathbf{x}\)</span> and summed over. The fancy term for this operation is a <em>dot product</em>. I’ll get into that more in the next lesson.</p>
</section>
<section id="matrix-multiplication" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="matrix-multiplication"><span class="header-section-number">5.3</span> Matrix Multiplication</h2>
<p>Matrix-vector multiplication is just a special case of the more general matrix multiplication. If <span class="math inline">\(\mathbf{A}\)</span> is an <span class="math inline">\(m \times n\)</span> matrix and <span class="math inline">\(\mathbf{B}\)</span> is an <span class="math inline">\(n \times p\)</span> matrix, we’ll define their <strong>matrix multiplication</strong> as a new <span class="math inline">\(m \times p\)</span> matrix <span class="math inline">\(\mathbf{C}\)</span> whose elements are given by</p>
<p><span class="math display">\[C_{i,j} = \sum_{k=0}^{n-1} A_{i,k} B_{k,j} = A_{i,0} B_{0,j} + A_{i,1} B_{1,j} + \cdots + A_{i,n-1} B_{n-1,j}.\]</span></p>
<p>Matrix multiplication is always expressed symbolically by directly concatenating the two matrix symbols next to each other like <span class="math inline">\(\mathbf{A}\mathbf{B}\)</span>. We’d never use a multiplication symbol between them since those are often used to represent other kinds of multiplication schemes like element-wise multiplication or convolutions. Further, matrix multiplication is only defined when the numbers of <em>columns</em> in <span class="math inline">\(\mathbf{A}\)</span> equals the number of <em>rows</em> of <span class="math inline">\(\mathbf{B}\)</span>. We say matrices satisfying this condition are <strong>compatible</strong>. If they can’t be multiplied, they’re called <strong>incompatible</strong>.</p>
<p>In words, matrix multiplication is the process where you take a <em>row</em> <span class="math inline">\(i\)</span> of the left matrix <span class="math inline">\(\mathbf{A}\)</span>, element-wise multiply it with a <em>column</em> <span class="math inline">\(j\)</span> of the right matrix <span class="math inline">\(\mathbf{B}\)</span>, and then sum up the results to get the entry <span class="math inline">\(C_{i,j}\)</span> of the output matrix <span class="math inline">\(\mathbf{C}\)</span>. Doing this for all pairs of rows and columns will fill in <span class="math inline">\(\mathbf{C}\)</span>.</p>
<p>Here’s an example where <span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(3 \times 3\)</span> and <span class="math inline">\(\mathbf{B}\)</span> is <span class="math inline">\(3 \times 2\)</span>. The output matrix <span class="math inline">\(\mathbf{C}\)</span> will be <span class="math inline">\(3 \times 2\)</span>.</p>
<p><span class="math display">\[
\begin{pmatrix}
    \color{red}{1} &amp; \color{red}{2} &amp; \color{red}{3} \\
    \color{blue}{4} &amp; \color{blue}{5} &amp; \color{blue}{6} \\
    \color{green}{7} &amp; \color{green}{8} &amp; \color{green}{9} \\
\end{pmatrix}
\begin{pmatrix}
    \color{orange}{6} &amp; \color{purple}{5} \\
    \color{orange}{4} &amp; \color{purple}{3} \\
    \color{orange}{2} &amp; \color{purple}{1} \\
\end{pmatrix} =
\begin{pmatrix}
   \color{red}{1} \color{black}{\cdot} \color{orange}{6} \color{black}{+} \color{red}{2} \color{black}{\cdot} \color{orange}{4} \color{black}{+} \color{red}{3} \color{black}{\cdot} \color{orange}{2} &amp; \color{red}{1} \color{black}{\cdot} \color{purple}{5} \color{black}{+} \color{red}{2} \color{black}{\cdot} \color{purple}{3} \color{black}{+} \color{red}{3} \color{black}{\cdot} \color{purple}{1} \\
   \color{blue}{4} \color{black}{\cdot} \color{orange}{6} \color{black}{+} \color{blue}{5} \color{black}{\cdot} \color{orange}{4} \color{black}{+} \color{blue}{6} \color{black}{\cdot} \color{orange}{2} &amp; \color{blue}{4} \color{black}{\cdot} \color{purple}{5} \color{black}{+} \color{blue}{5} \color{black}{\cdot} \color{purple}{3} \color{black}{+} \color{blue}{6} \color{black}{\cdot} \color{purple}{1} \\
   \color{green}{7} \color{black}{\cdot} \color{orange}{6} \color{black}{+} \color{green}{8} \color{black}{\cdot} \color{orange}{4} \color{black}{+} \color{green}{9} \color{black}{\cdot} \color{orange}{2} &amp; \color{green}{7} \color{black}{\cdot} \color{purple}{5} \color{black}{+} \color{green}{8} \color{black}{\cdot} \color{purple}{3} \color{black}{+} \color{green}{9} \color{black}{\cdot} \color{purple}{1} \\
\end{pmatrix} =
\begin{pmatrix}
   20 &amp; 14 \\
   56 &amp; 41 \\
   92 &amp; 68 \\
\end{pmatrix}.
\]</span></p>
<p><strong>Aside:</strong> If you’re still having a hard time picturing what matrix multiplication is doing, you may find <a href="http://matrixmultiplication.xyz/">this</a> online visualization tool useful.</p>
<p>Note that matrix multiplication does not <strong>commute</strong>. That is, we can’t swap the order of the two matrices being multiplied, <span class="math inline">\(\mathbf{A}\mathbf{B} \neq \mathbf{B}\mathbf{A}\)</span>. Try to multiply the previous example in the opposite order and see what happens. The matrices won’t even be compatible anymore.</p>
<p>However, matrix multiplication is <strong>associative</strong>, which means you can group parentheses just like you ordinarily would. For example, multiplying three matrices <span class="math inline">\(\mathbf{A}, \mathbf{B}, \mathbf{C}\)</span> could be done by multiplying either the first two, and then the last; or the last two, and then the first. That is,</p>
<p><span class="math display">\[\mathbf{A}\mathbf{B}\mathbf{C} = \mathbf{A}(\mathbf{B}\mathbf{C}) = (\mathbf{A}\mathbf{B})\mathbf{C}.\]</span></p>
<section id="matrix-multiplication-algorithm" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="matrix-multiplication-algorithm"><span class="header-section-number">5.3.1</span> Matrix Multiplication Algorithm</h3>
<p>Matrix multiplication is perhaps the single most important mathematical operation in machine learning. It’s so important I’m going to write a function to code it from scratch before showing how to do it in numpy. I’ll also analyze the speed of the algorithm in FLOPS and the memory in terms of word size. Algorithmically, all matrix multiplication is doing is looping over every single element of <span class="math inline">\(\mathbf{C}\)</span> and performing the sum-product calculation above for each <span class="math inline">\(C_{i,j}\)</span>. I’ll define a function called <code>matmul</code> that takes in two numpy arrays <code>A</code> and <code>B</code> and multiplies them, returning the product <code>C</code> if the dimensions are compatible.</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> matmul(A, B):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> A.shape[<span class="dv">1</span>] <span class="op">==</span> B.shape[<span class="dv">0</span>]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    m, n, p <span class="op">=</span> A.shape[<span class="dv">0</span>], A.shape[<span class="dv">1</span>], B.shape[<span class="dv">1</span>]</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> np.zeros((m, p))</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(m):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(p):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>                C[i, j] <span class="op">+=</span> A[i, k] <span class="op">*</span> B[k, j]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> C</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>], [<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>]])<span class="op">;</span> <span class="bu">print</span>(<span class="ss">f'A = </span><span class="ch">\n</span><span class="sc">{</span>A<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.array([[<span class="dv">6</span>, <span class="dv">5</span>], [<span class="dv">4</span>, <span class="dv">3</span>], [<span class="dv">2</span>, <span class="dv">1</span>]])<span class="op">;</span> <span class="bu">print</span>(<span class="ss">f'B = </span><span class="ch">\n</span><span class="sc">{</span>B<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> matmul(A, B)<span class="op">;</span> <span class="bu">print</span>(<span class="ss">f'C = AB = </span><span class="ch">\n</span><span class="sc">{</span>C<span class="sc">.</span>astype(A.dtype)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>A = 
[[1 2 3]
 [4 5 6]
 [7 8 9]]
B = 
[[6 5]
 [4 3]
 [2 1]]
C = AB = 
[[20 14]
 [56 41]
 [92 68]]</code></pre>
</div>
</div>
<p>Let’s take a quick look at what this function is doing complexity wise. First off, we’re pre-computing the output matrix <span class="math inline">\(\mathbf{C}\)</span>. That’ll contribute <span class="math inline">\(O(mp)\)</span> memory since <span class="math inline">\(\mathbf{C}\)</span> is <span class="math inline">\(m \times p\)</span>. All of the FLOPS are happening inside the double loop over <span class="math inline">\(m\)</span> and <span class="math inline">\(p\)</span>. For each <span class="math inline">\(i,j\)</span> pair, the function is doing <span class="math inline">\(n\)</span> total multiplications and <span class="math inline">\(n-1\)</span> total additions, which means there’s <span class="math inline">\(2n-1\)</span> FLOPs per <span class="math inline">\(i,j\)</span> pair. Since we’re doing this operation <span class="math inline">\(m \cdot p\)</span> times, we’re thus doing <span class="math inline">\(m \cdot p \cdot (2n-1)\)</span> total FLOPS in the matrix multiply. This gives us an <span class="math inline">\(O(nmp)\)</span> algorithm in general. Matrix multiplication is an example of a <em>cubic time</em> algorithm since if <span class="math inline">\(n=m=p\)</span> we’d have a <span class="math inline">\(O(n^3)\)</span> FLOPS operation.</p>
<p><strong>Aside:</strong> People have found algorithms that can matrix multiply somewhat faster than cubic time. For example, <a href="https://en.wikipedia.org/wiki/Strassen_algorithm">Strassen’s algorithm</a> can matrix multiply in about <span class="math inline">\(O(n^{2.8})\)</span> time. In practice, though, these algorithms tend to have large constants out front, which means they’re not that useful unless <span class="math inline">\(n\)</span> is <em>huge</em>. If the matrices have special structure, e.g.&nbsp;banded matrices or sparse matrices, they have special algorithms that can multiply them even faster, for example by using the <a href="https://en.wikipedia.org/wiki/Fast_Fourier_transform">Fast Fourier Transform</a>, which can matrix multiply as fast as <span class="math inline">\(O(n^2 \log^2 n)\)</span>. This is what, for example, convolutional neural networks use.</p>
<p>Cubic time may seem fast since it’s polynomial time, but it’s really not that great unless the matrices are relatively small (say <span class="math inline">\(n \leq 1000\)</span> or so). For this reason, a lot of effort has instead gone into pushing down the algorithmic constant out front, e.g.&nbsp;by doing special hardware optimizations like SIMD, optimizing matrix blocks to take advantage of memory efficiency, or heavily parallelizing the operation by doing the inner loops in parallel. It’s also a good idea to push operations down to low-level compiled code written in FORTRAN or C, which is what numpy essentially does.</p>
<p>In the age of deep learning we’re finding ourselves needing to multiply a lot of matrices and needing to do it quickly. This has been enabled largely through the use of GPUs to do array computations. GPUs are essentially specially built hardware just to do array operations like matrix multiplication efficiently. It’s no exaggeration in fact to say that the recent deep learning revolution happened precisely because of GPUs.</p>
<p>Anyway, we’d never want to implement matrix multiplication natively in python like this. It’s far too most of the time. In practice we’d use something like <code>np.matmul(A, B)</code>. Numpy also supports a cleaner syntax using the <code>@</code> operator. This means we can also express the matrix multiply as <code>A @ B</code>, which means exactly the same thing as <code>np.matmul(A, B)</code>, just with cleaner syntax. This syntax is what I’ll typically use in this book.</p>
<p>Here’s an example. I’ll multiply the same two matrices from before, but this time using numpy. To show it’s faster than native python matmul, I’ll run a quick profiler as well. You can see that even with these small matrices we’re still getting a 10x speedup using numpy over base python. The speedup can get up to 100x and higher for much larger matrices.</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> A <span class="op">@</span> B</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'C = </span><span class="ch">\n</span><span class="sc">{</span>C<span class="sc">.</span>astype(A.dtype)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>C = 
[[20 14]
 [56 41]
 [92 68]]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit matmul(A, B)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>11.2 µs ± 14 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit A <span class="op">@</span> B</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>892 ns ± 4.44 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)</code></pre>
</div>
</div>
</section>
<section id="chained-matrix-multiplication" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="chained-matrix-multiplication"><span class="header-section-number">5.3.2</span> Chained Matrix Multiplication</h3>
<p>What if we’d like to multiply three or more matrices together. I already said matrix multiplication is associative, so <em>in theory</em> we should be able to matrix multiply in any order and get the same answer. However, there are often computational advantages to multiplying them together in some particular sequence. For example, suppose we wanted to multiply <span class="math inline">\(\mathbf{D} = \mathbf{A}\mathbf{B}\mathbf{C}\)</span>. Suppose, <span class="math inline">\(\mathbf{A}\)</span> is <span class="math inline">\(m \times n\)</span>, <span class="math inline">\(\mathbf{B}\)</span> is <span class="math inline">\(n \times p\)</span>, and <span class="math inline">\(\mathbf{C}\)</span> is <span class="math inline">\(p \times q\)</span>. No matter which order we do it, the output <span class="math inline">\(\mathbf{D}\)</span> will have size <span class="math inline">\(m \times q\)</span>. But there are two ways we could do this multiplication.</p>
<ol type="1">
<li><p><span class="math inline">\(\mathbf{D} = \mathbf{A}(\mathbf{B}\mathbf{C})\)</span>: In this case, the <span class="math inline">\(\mathbf{E}=\mathbf{B}\mathbf{C}\)</span> computation requires <span class="math inline">\(nq(2p-1)\)</span> FLOPS, and then the <span class="math inline">\(\mathbf{A}\mathbf{E}\)</span> computation requires <span class="math inline">\(mq(2n-1)\)</span> FLOPS. The total is thus the sum of these two, i.e. <span class="math display">\[nq(2p-1) + mq(2n-1) = O(npq+mnq) \ \ \text{FLOPS}.\]</span></p></li>
<li><p><span class="math inline">\(\mathbf{D} = (\mathbf{A}\mathbf{B})\mathbf{C}\)</span>: In this case, the <span class="math inline">\(\mathbf{F}=\mathbf{A}\mathbf{B}\)</span> computation requires <span class="math inline">\(mp(2n-1)\)</span> FLOPS, and then the <span class="math inline">\(\mathbf{F}\mathbf{C}\)</span> computation requires <span class="math inline">\(mq(2n-1)\)</span> FLOPS. The total is thus the sum of these two, i.e. <span class="math display">\[mq(2p-1) + mp(2n-1) = O(mpq+mnp) \ \ \text{FLOPS}.\]</span></p></li>
</ol>
<p>Let’s put some numbers in to make it clear what’s going on. Suppose <span class="math inline">\(m=1000\)</span>, <span class="math inline">\(n=2\)</span>, <span class="math inline">\(p=100\)</span>, and <span class="math inline">\(q=100\)</span>. Then the first case takes</p>
<p><span class="math display">\[nq(2p-1) + mq(2n-1) = 339800 \ \ \text{FLOPS},\]</span></p>
<p>while the second case takes a staggering</p>
<p><span class="math display">\[mq(2p-1) + mp(2n-1) = 20200000 \ \ \text{FLOPS}.\]</span></p>
<p>It would thus behoove us in this case to multiply the matrices in the first order to save on computation, <span class="math inline">\(\mathbf{D} = \mathbf{A}(\mathbf{B}\mathbf{C})\)</span>. Here’s a programmatic way to see this.</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'A(BC): </span><span class="sc">{</span>m <span class="op">*</span> q <span class="op">*</span> (<span class="dv">2</span> <span class="op">*</span> n <span class="op">-</span> <span class="dv">1</span>) <span class="op">+</span> n <span class="op">*</span> q <span class="op">*</span> (<span class="dv">2</span> <span class="op">*</span> p <span class="op">-</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> FLOPS'</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'(AB)C: </span><span class="sc">{</span>m <span class="op">*</span> p <span class="op">*</span> (<span class="dv">2</span> <span class="op">*</span> n <span class="op">-</span> <span class="dv">1</span>) <span class="op">+</span> m <span class="op">*</span> q <span class="op">*</span> (<span class="dv">2</span> <span class="op">*</span> p <span class="op">-</span> <span class="dv">1</span>)<span class="sc">}</span><span class="ss"> FLOPS'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>A(BC): 339800 FLOPS
(AB)C: 20200000 FLOPS</code></pre>
</div>
</div>
<p>The same issues extend to multiplying together arbitrarily many matrices. You can save <em>a lot</em> of compute by first taking time to find the optimal order to multiply them together before doing the computation. Don’t just naively multiply them in order. Numpy has a function <code>np.linalg.multi_dot</code> that can do this for you. If you pass in a list of matrices, it’ll multiply them together in the most efficient order to help save on computation. Here’s an example. I’ll profile the different ways we can do the <span class="math inline">\(\mathbf{A}\mathbf{B}\mathbf{C}\)</span> example above. Notice that indeed <span class="math inline">\(\mathbf{A}(\mathbf{B}\mathbf{C})\)</span> is much faster than <span class="math inline">\((\mathbf{A}\mathbf{B})\mathbf{C}\)</span>. The <code>multi_dot</code> solution is roughly as fast as the <span class="math inline">\(\mathbf{A}(\mathbf{B}\mathbf{C})\)</span> solution, but it does take slightly longer because it first calculates the optimal ordering, which adds a little bit of time.</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.random.rand(m, n)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.random.rand(n, p)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> np.random.rand(p, q)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit A <span class="op">@</span> (B <span class="op">@</span> C)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>64.8 µs ± 37.2 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit (A <span class="op">@</span> B) <span class="op">@</span> C</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>526 µs ± 14 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>timeit np.linalg.multi_dot([A, B, C])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>78.2 µs ± 223 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)</code></pre>
</div>
</div>
</section>
<section id="matrix-multiplication-vs-element-wise-multiplication" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="matrix-multiplication-vs-element-wise-multiplication"><span class="header-section-number">5.3.3</span> Matrix Multiplication vs Element-Wise Multiplication</h3>
<p>We’ve already seen a different way we can multiply two matrices (or any array), namely element-wise multiplication. For matrices, element-wise multiplication is sometimes called the <strong>Hadamard product</strong>. I’ll denote element-wise multiplication as <span class="math inline">\(\mathbf{A} \circ \mathbf{B}\)</span>. Note that element-wise multiplication is only defined when the shapes of <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> are <em>exactly equal</em> (or can be broadcasted to be equal).</p>
<p>It’s important to mind the difference between matrix multiplication and element-wise multiplication of matrices. In general <span class="math inline">\(\mathbf{A} \circ \mathbf{B} \neq \mathbf{A} \mathbf{B}\)</span>. They’re defined completely differently,</p>
<p><span class="math display">\[\begin{align*}
(A \circ B)_{i,j} &amp;= A_{i,j} \cdot B_{i,j} \\
(AB)_{i,j} &amp;= \sum_k A_{i,k}B_{k,j}.
\end{align*}\]</span></p>
<p>In numpy use <code>A * B</code> for element-wise multiplication and <code>A @ B</code> for matrix multiplication. To make it clear the two kinds of multiplication aren’t the same thing here’s an example.</p>
<div class="cell" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]])</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">1</span>]])</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'A*B = </span><span class="ch">\n</span><span class="sc">{</span>A <span class="op">*</span> B<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'AB = </span><span class="ch">\n</span><span class="sc">{</span>A <span class="op">@</span> B<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>A*B = 
[[1 0]
 [0 4]]
AB = 
[[1 2]
 [3 4]]</code></pre>
</div>
</div>
</section>
<section id="interpreting-matrix-multiplication" class="level3" data-number="5.3.4">
<h3 data-number="5.3.4" class="anchored" data-anchor-id="interpreting-matrix-multiplication"><span class="header-section-number">5.3.4</span> Interpreting Matrix Multiplication</h3>
<p>This stuff might seem kind of abstract so far. Why should we care about multiplying matrices? I’ll say more about that in the next lesson, but for now I want to mention a useful way to interpret matrix-vector multiplication and matrix multiplication, a way that you almost certainly never learned in school when you were taught about matrices.</p>
<p>We can think about a matrix in a few different ways. One way is just as a 2-dimensional array of numbers. We can also think of it as a stack of vectors. If <span class="math inline">\(\mathbf{A}\)</span> is an <span class="math inline">\(m \times n\)</span>, we can think of each <em>column</em> of <span class="math inline">\(\mathbf{A}\)</span> as being a vector of size <span class="math inline">\(m \times 1\)</span>. These are called the <strong>column vectors</strong> of <span class="math inline">\(\mathbf{A}\)</span>. We can also think about each <em>row</em> of <span class="math inline">\(\mathbf{A}\)</span> as being a vector of size <span class="math inline">\(1 \times n\)</span>. These are called the <strong>row vectors</strong> of <span class="math inline">\(\mathbf{A}\)</span>. In keeping with the python convention, I’ll denote the column vectors of <span class="math inline">\(\mathbf{A}\)</span> by <span class="math inline">\(\mathbf{A}_{:, i}\)</span>, and the row vectors of <span class="math inline">\(\mathbf{A}\)</span> by <span class="math inline">\(\mathbf{A}_{i, :}\)</span>. Notice the use of the slice operator <span class="math inline">\(:\)</span> here, which means “take everything in that dimension”.</p>
<p>Here’s an example. Take <span class="math inline">\(\mathbf{A}\)</span> to be the following <span class="math inline">\(2 \times 3\)</span> matrix,</p>
<p><span class="math display">\[
\mathbf{A} =
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6
\end{pmatrix}.
\]</span></p>
<p>The <em>column</em> vectors of <span class="math inline">\(\mathbf{A}\)</span> are just</p>
<p><span class="math display">\[\mathbf{A}_{:, 0} = \begin{pmatrix} 1 \\ 4 \end{pmatrix}, \quad \mathbf{A}_{:, 1} = \begin{pmatrix} 2 \\ 5 \end{pmatrix}, \quad \mathbf{A}_{:, 2} = \begin{pmatrix} 3 \\ 6 \end{pmatrix},\]</span></p>
<p>And the <em>row</em> vectors of <span class="math inline">\(\mathbf{A}\)</span> are just</p>
<p><span class="math display">\[\mathbf{A}_{0, :} = \begin{pmatrix} 1 &amp; 2 &amp; 3 \end{pmatrix}, \quad \mathbf{A}_{1, :} = \begin{pmatrix} 4 &amp; 5 &amp; 6 \end{pmatrix}.\]</span></p>
<p>Using the column vectors of <span class="math inline">\(\mathbf{A}\)</span> we can think about the matrix multiplication <span class="math inline">\(\mathbf{A} \mathbf{x}\)</span> in an interesting way. If there are <span class="math inline">\(n\)</span> total column vectors, we can write</p>
<p><span class="math display">\[
\mathbf{A} \mathbf{x} =
\begin{pmatrix}
\mathbf{A}_{:, 0} &amp; \mathbf{A}_{:, 1} &amp; \cdots &amp; \mathbf{A}_{:, n-1}
\end{pmatrix}
\begin{pmatrix}
x_0 \\
x_1 \\
\vdots \\
x_{n-1}
\end{pmatrix} =
x_0 \mathbf{A}_{:, 0} + x_1 \mathbf{A}_{:, 1} + \cdots x_{n-1} \mathbf{A}_{:, n-1}.
\]</span></p>
<p>Evidently, we can think of <span class="math inline">\(\mathbf{A} \mathbf{x}\)</span> as some kind of mixture of the columns of <span class="math inline">\(\mathbf{A}\)</span>, weighted by the elements of <span class="math inline">\(\mathbf{x}\)</span>. Such a mixture is called a <strong>linear combination</strong>. In this terminology, we’d say that the matrix-vector multiplication <span class="math inline">\(\mathbf{A} \mathbf{x}\)</span> is a linear combination of the columns of <span class="math inline">\(\mathbf{A}\)</span>.</p>
<p>For example, if <span class="math inline">\(\mathbf{A}\)</span> is the <span class="math inline">\(2 \times 3\)</span> matrix from the previous example and <span class="math inline">\(\mathbf{x} = \begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}\)</span>, we’d have</p>
<p><span class="math display">\[
\mathbf{A} \mathbf{x} =
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6
\end{pmatrix}
\begin{pmatrix}
1 \\
1 \\
1
\end{pmatrix} = 1 \cdot \binom{1}{4} + 1 \cdot \binom{2}{5} + 1 \cdot \binom{3}{6} = \binom{1+2+3}{4+5+6} = \binom{6}{15}.
\]</span></p>
<p>We can think of matrix multiplication in a similar way. Suppose we want to multiply two matrices <span class="math inline">\(\mathbf{A} \mathbf{X}\)</span>. You can think of <span class="math inline">\(\mathbf{X}\)</span> as itself being a bunch of different column vectors <span class="math inline">\(\mathbf{X}_{:, i}\)</span>, where for each of those column vectors we’re doing a matrix-vector multiplication <span class="math inline">\(\mathbf{A}\mathbf{X}_{:, i}\)</span>. That is, matrix multiplication is just a <em>batch</em> of weighted linear combinations of the columns of <span class="math inline">\(\mathbf{A}\)</span>,</p>
<p><span class="math display">\[
\begin{array}{c&lt;{x_0} c c&lt;{x_1} c c&lt;{\cdots} c c&lt;{x_{n-1}} c l}
\mathbf{A} \mathbf{X}_{:, 0} &amp; = &amp; X_{0,0} \mathbf{A}_{:, 0} &amp; + &amp; X_{1,0} \mathbf{A}_{:, 1} &amp; + &amp; \cdots &amp; + &amp; X_{m-1,0} \mathbf{A}_{:, n-1} \\
\mathbf{A} \mathbf{X}_{:, 1} &amp; = &amp; X_{0,1} \mathbf{A}_{:, 0} &amp; + &amp; X_{1,1} \mathbf{A}_{:, 1} &amp; + &amp; \cdots &amp; + &amp; X_{m-1,1} \mathbf{A}_{:, n-1} \\
\vdots &amp; &amp; \vdots    &amp;   &amp; \vdots    &amp;   &amp;  \ddots  &amp;   &amp; \quad \vdots\\
\mathbf{A} \mathbf{X}_{:, n-1} &amp; = &amp; X_{0,n-1} \mathbf{A}_{:, 0} &amp; + &amp; X_{1,n-1} \mathbf{A}_{:, 1} &amp; + &amp; \cdots &amp; + &amp; X_{m-1,n-1} \mathbf{A}_{:, n-1}. \\
\end{array}
\]</span></p>
<p>These aren’t the only ways to interpret what matrix multiplication is doing. I’ll cover a more geometric interpretation later, where it’ll turn out that matrix multiplication is the same thing as the composition of linear maps.</p>
</section>
</section>
<section id="solving-linear-systems" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="solving-linear-systems"><span class="header-section-number">5.4</span> Solving Linear Systems</h2>
<p>One of the most important things we’d like to do with linear systems is solve for their inputs. Suppose we have a linear equation of the form <span class="math inline">\(ax=b\)</span> and we wanted to solve for <span class="math inline">\(x\)</span>. It’s clear in this case what we’d do. Provided <span class="math inline">\(a \neq 0\)</span>, we’d divide both sides by <span class="math inline">\(a\)</span> to get</p>
<p><span class="math display">\[x = \frac{b}{a} = a^{-1} b.\]</span></p>
<p>We’d like to be able to do something like this for an <span class="math inline">\(m \times n\)</span> linear system <span class="math inline">\(\mathbf{Ax} = \mathbf{b}\)</span>. But dividing by a matrix doesn’t really make sense. We need to figure out another way to proceed.</p>
<section id="square-linear-systems" class="level3" data-number="5.4.1">
<h3 data-number="5.4.1" class="anchored" data-anchor-id="square-linear-systems"><span class="header-section-number">5.4.1</span> Square Linear Systems</h3>
<p>Perhaps it would help to recall how we’d solve a system of equations. Suppose for example we have the following system of 2 linear equations with 2 unknowns <span class="math inline">\(x_0\)</span> and <span class="math inline">\(x_1\)</span>,</p>
<p><span class="math display">\[\begin{alignat*}{3}
   x_0 &amp; {}+{} &amp;  x_1 &amp; {}={} &amp; 2  \\
   x_0 &amp; {}-{} &amp;  x_1 &amp; {}={} &amp; 0. \\
\end{alignat*}\]</span></p>
<p>Using the method that pretty much always works, substitution, we can solve these one at a time. The second equation says <span class="math inline">\(x_0 = x_1\)</span>. Plugging this into the first equation then says <span class="math inline">\(x_0=x_1=1\)</span>, which is our solution. This is an example of the more general <span class="math inline">\(2 \times 2\)</span> linear system</p>
<p><span class="math display">\[\begin{alignat*}{3}
   ax_0 &amp; {}+{} &amp;  bx_1 &amp; {}={} &amp; e \\
   cx_0 &amp; {}+{} &amp;  dx_1 &amp; {}={} &amp; f.
\end{alignat*}\]</span></p>
<p>This can be solved by substitution too, but I’ll spare you the details and use sympy to get the answer. It’s given by</p>
<p><span class="math display">\[\begin{align*}
x_0 &amp;= \frac{de-bf}{ad-bc} \\
x_1 &amp;= \frac{af-ce}{ad-bc}.
\end{align*}\]</span></p>
<div class="cell" data-execution_count="15">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>x0, x1 <span class="op">=</span> sp.symbols(<span class="st">'x_0 x_1'</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>a, b, c, d, e, f <span class="op">=</span> sp.symbols(<span class="st">'a b c d e f'</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>eq1 <span class="op">=</span> sp.Eq(a <span class="op">*</span> x0 <span class="op">+</span> b <span class="op">*</span> x1, e)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>eq2 <span class="op">=</span> sp.Eq(c <span class="op">*</span> x0 <span class="op">+</span> d <span class="op">*</span> x1, f)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>sol <span class="op">=</span> sp.solve((eq1, eq2), (x0, x1))</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'x0 = </span><span class="sc">{</span>sol[x0]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'x1 = </span><span class="sc">{</span>sol[x1]<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>x0 = (-b*f + d*e)/(a*d - b*c)
x1 = (a*f - c*e)/(a*d - b*c)</code></pre>
</div>
</div>
<p>It’s worth plotting what these equations look like to try to visualize what’s going on. Let’s look again at the specific set of equations</p>
<p><span class="math display">\[\begin{alignat*}{3}
   x_0 &amp; {}+{} &amp;  x_1 &amp; {}={} &amp; 2  \\
   x_0 &amp; {}-{} &amp;  x_1 &amp; {}={} &amp; 0. \\
\end{alignat*}\]</span></p>
<p>Each of these equations corresponds to a line in the plane, namely</p>
<p><span class="math display">\[y = 2 - x, \quad y = x.\]</span></p>
<p>If we plot these two lines, the point where they intersect is <span class="math inline">\((1,1)\)</span>, which is the solution to the linear system.</p>
<div class="cell" data-execution_count="16">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>f0 <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">2</span> <span class="op">-</span> x</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> <span class="kw">lambda</span> x: x</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>plot_function(x, [f0, f1], xlim<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">3</span>), ylim<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">3</span>), title<span class="op">=</span><span class="st">'2 Linear Equations, 2 Unknowns'</span>,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>              labels<span class="op">=</span>[<span class="ss">f'$y=2-x$'</span>, <span class="ss">f'$y=x$'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="linear-systems_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>More generally, the coefficients <span class="math inline">\(a,b,c,d,e,f\)</span> represent the slopes and intercepts of the two lines. Changing any of these will change the point of intersection, and hence also the solution to the <span class="math inline">\(2 \times 2\)</span> system. Notice there is one edge case, namely when <span class="math inline">\(ad=bc\)</span>. This is when the two lines are parallel. Since parallel lines don’t intersect, such a system would have no solution. You can also see this by noticing that the denominator for <span class="math inline">\(x_0\)</span> and <span class="math inline">\(x_1\)</span> blows up, since <span class="math inline">\(D=ad-bc=0\)</span>. These denominators are special. They essentially say whether or not a solution to a given linear system will even exist.</p>
<p>Let’s look now at the general <span class="math inline">\(3 \times 3\)</span> linear system</p>
<p><span class="math display">\[\begin{alignat*}{5}
   ax_0 &amp; {}+{} &amp;  bx_1 &amp; {}+{} &amp; cx_2 {}={} &amp; j \\
   dx_0 &amp; {}+{} &amp;  ex_1 &amp; {}+{} &amp; fx_2 {}={} &amp; k \\
   gx_0 &amp; {}+{} &amp;  hx_1 &amp; {}+{} &amp; ix_2 {}={} &amp; l.
\end{alignat*}\]</span></p>
<p>According to sympy, the solution to this system is evidently this monstrosity,</p>
<p><span class="math display">\[\begin{align*}
x_0 &amp;= \frac{bfl - bik - cel + chk + eij - fhj}{aei - afh - bdi + bfg + cdh - ceg} \\
x_1 &amp;= \frac{-afl + aik + cdl - cgk - dij + fgj}{aei - afh - bdi + bfg + cdh - ceg} \\
x_2 &amp;= \frac{ael - ahk - bdl + bgk + dhj - egj}{aei - afh - bdi + bfg + cdh - ceg}. \\
\end{align*}\]</span></p>
<div class="cell" data-execution_count="17">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>x0, x1, x2 <span class="op">=</span> sp.symbols(<span class="st">'x_0 x_1 x_2'</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>a, b, c, d, e, f, g, h, i, j, k, l <span class="op">=</span> sp.symbols(<span class="st">'a b c d e f g h i j k l'</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>eq1 <span class="op">=</span> sp.Eq(a <span class="op">*</span> x0 <span class="op">+</span> b <span class="op">*</span> x1 <span class="op">+</span> c <span class="op">*</span> x2, j)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>eq2 <span class="op">=</span> sp.Eq(d <span class="op">*</span> x0 <span class="op">+</span> e <span class="op">*</span> x1 <span class="op">+</span> f <span class="op">*</span> x2, k)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>eq3 <span class="op">=</span> sp.Eq(g <span class="op">*</span> x0 <span class="op">+</span> h <span class="op">*</span> x1 <span class="op">+</span> i <span class="op">*</span> x2, l)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>sol <span class="op">=</span> sp.solve((eq1, eq2, eq3), (x0, x1, x2))</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'x0 = </span><span class="sc">{</span>sol[x0]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'x1 = </span><span class="sc">{</span>sol[x1]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'x2 = </span><span class="sc">{</span>sol[x2]<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>x0 = (b*f*l - b*i*k - c*e*l + c*h*k + e*i*j - f*h*j)/(a*e*i - a*f*h - b*d*i + b*f*g + c*d*h - c*e*g)
x1 = (-a*f*l + a*i*k + c*d*l - c*g*k - d*i*j + f*g*j)/(a*e*i - a*f*h - b*d*i + b*f*g + c*d*h - c*e*g)
x2 = (a*e*l - a*h*k - b*d*l + b*g*k + d*h*j - e*g*j)/(a*e*i - a*f*h - b*d*i + b*f*g + c*d*h - c*e*g)</code></pre>
</div>
</div>
<p>Ignore the details of this thing. Just notice the fact that all three unknowns seem to again have the same denominator, in this case</p>
<p><span class="math display">\[D = aei - afh - bdi + bfg + cdh - ceg.\]</span></p>
<p>If <span class="math inline">\(D=0\)</span>, the <span class="math inline">\(3 \times 3\)</span> system will have no solution. I can keep going, next to <span class="math inline">\(4 \times 4\)</span> systems, then <span class="math inline">\(5 \times 5\)</span> systems, but hopefully you get the point. There will always be a common denominator <span class="math inline">\(D\)</span> in the solutions that can’t be zero. These denominators have a name. They’re called <strong>determinants</strong>. If <span class="math inline">\(\mathbf{A}\)</span> is the <span class="math inline">\(n \times n\)</span> matrix of coefficients, we’ll denote its determinant by <span class="math inline">\(\det(\mathbf{A})\)</span> or sometimes just by <span class="math inline">\(|\mathbf{A}|\)</span>. We’ve thus stumbled on a general fact.</p>
<p><strong>Fact:</strong> An <span class="math inline">\(n \times n\)</span> system of linear equations <span class="math inline">\(\mathbf{Ax}=\mathbf{b}\)</span> where <span class="math inline">\(\mathbf{b} \neq \mathbf{0}\)</span> has a solution if and only if <span class="math inline">\(\det(\mathbf{A}) \neq 0\)</span>. In fact, this solution is <em>unique</em>.</p>
<p>Note there’s an edge case when <span class="math inline">\(\mathbf{b} = \mathbf{0}\)</span> and <span class="math inline">\(\det(\mathbf{A}) \neq 0\)</span>. In that one case, there will be infinitely many solutions. You can think of this as the situation where the solutions have a <span class="math inline">\(\frac{0}{0}\)</span>, which is the one case where dividing by <span class="math inline">\(0\)</span> could still give a finite number.</p>
<p>Before moving on, let’s visualize what the <span class="math inline">\(3 \times 3\)</span> linear system looks like. Consider the following specific example,</p>
<p><span class="math display">\[\begin{alignat*}{5}
   3x_0 &amp; {}+{} &amp;  2x_1 &amp; {}+{} &amp; x_2 {}={} &amp; 0 \\
   x_0 &amp; {}+{} &amp;  x_1 &amp; {}-{} &amp; x_2 {}={} &amp; 1 \\
   x_0 &amp; {}-{} &amp;  3x_1 &amp; {}-{} &amp; x_3 {}={} &amp; -3. \\
\end{alignat*}\]</span></p>
<p>Again using substitution, you can solve each equation one by one to check that this system has a solution at <span class="math inline">\(x_0=-\frac{1}{2}\)</span>, <span class="math inline">\(x_1=1\)</span>, and <span class="math inline">\(x_2=-\frac{1}{2}\)</span>. The three equations above form a set of three planes given by</p>
<p><span class="math display">\[\begin{align*}
z &amp;= -3x - 2y + 0, \\
z &amp;= x + y - 1, \\
z &amp;= 4 . \\
\end{align*}\]</span></p>
<p>The solution to this <span class="math inline">\(3 \times 3\)</span> system will be the point where all three of these planes intersect. It’s a perhaps a little hard to see in the plot, but hopefully you get the point. In general, the solution of an <span class="math inline">\(n \times n\)</span> linear system will occur at the point where the set of <span class="math inline">\(n\)</span> hyperplanes all intersect. If any two of the hyperplanes are parallel, the determinant will be zero, and there won’t be a solution.</p>
<div class="cell" data-execution_count="18">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">1.5</span>, <span class="dv">100</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">100</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> <span class="kw">lambda</span> x, y: <span class="op">-</span><span class="dv">3</span> <span class="op">*</span> x <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> y <span class="op">+</span> <span class="dv">0</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>f2 <span class="op">=</span> <span class="kw">lambda</span> x, y: x <span class="op">+</span> y <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>f3 <span class="op">=</span> <span class="kw">lambda</span> x, y: x <span class="op">-</span> <span class="dv">3</span> <span class="op">*</span> y <span class="op">+</span> <span class="dv">3</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>plot_function_3d(x, y, [f1, f2, f3], azim<span class="op">=</span><span class="dv">65</span>, elev<span class="op">=</span><span class="dv">25</span>, ticks_every<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">3</span>], figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>), zorders<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>],</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>                 colors<span class="op">=</span>[<span class="st">'steelblue'</span>, <span class="st">'salmon'</span>, <span class="st">'limegreen'</span>], points<span class="op">=</span>[[<span class="op">-</span><span class="fl">0.5</span>, <span class="dv">1</span>, <span class="op">-</span><span class="fl">0.5</span>]], alpha<span class="op">=</span><span class="fl">0.6</span>, labelpad<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>                 dist<span class="op">=</span><span class="dv">11</span>, title<span class="op">=</span><span class="st">'3 Equations, 3 Unknowns'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="linear-systems_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Let’s now try to see if we can figure out a pattern, a way to systematically solve these linear systems. Let’s start by going back to the easy <span class="math inline">\(2 \times 2\)</span> case. Recall that the linear system</p>
<p><span class="math display">\[\begin{alignat*}{3}
   ax_0 &amp; {}+{} &amp;  bx_1 &amp; {}={} &amp; e \\
   cx_0 &amp; {}+{} &amp;  dx_1 &amp; {}={} &amp; f. \\
\end{alignat*}\]</span></p>
<p>has solutions given by</p>
<p><span class="math display">\[\begin{align*}
x_0 &amp;= \frac{de-bf}{ad-bc} \\
x_1 &amp;= \frac{af-ce}{ad-bc}. \\
\end{align*}\]</span></p>
<p>Now, if we write this <span class="math inline">\(2 \times 2\)</span> linear system in matrix-vector notation, we’d have</p>
<p><span class="math display">\[
\mathbf{A}\mathbf{x} =
\begin{pmatrix}
a &amp; b \\
c &amp; d
\end{pmatrix}
\begin{pmatrix}
x_0 \\
x_1
\end{pmatrix} =
\begin{pmatrix}
e \\
f
\end{pmatrix}
= \mathbf{b},
\]</span></p>
<p>and the solutions would look like</p>
<p><span class="math display">\[
\mathbf{x} =
\begin{pmatrix}
x_0 \\
x_1
\end{pmatrix} =
\begin{pmatrix}
\frac{de-bf}{ad-bc} \\
\frac{af-ce}{ad-bc}
\end{pmatrix}.
\]</span></p>
<p>I’m going to manipulate the solutions so they have a suggestible form. Observe that we can write</p>
<p><span class="math display">\[
\mathbf{x} =
\begin{pmatrix}
x_0 \\
x_1
\end{pmatrix} =
\begin{pmatrix}
\frac{de-bf}{ad-bc} \\
\frac{af-ce}{ad-bc}
\end{pmatrix} =
\begin{pmatrix}
\frac{d}{ad-bc} &amp; -\frac{b}{ad-bc} \\
-\frac{c}{ad-bc} &amp; \frac{a}{ad-bc}
\end{pmatrix}
\begin{pmatrix}
e \\
f
\end{pmatrix} =
\frac{1}{ad-bc}
\begin{pmatrix}
d &amp; -b \\
-c &amp; a
\end{pmatrix}
\begin{pmatrix}
e \\
f
\end{pmatrix}.
\]</span></p>
<p>On the right-hand side, we seem to have some kind of matrix times the vector <span class="math inline">\(\mathbf{b}\)</span>. Whatever that matrix is, it seems to “undo” <span class="math inline">\(\mathbf{A}\)</span>. Let’s call that matrix <span class="math inline">\(\mathbf{A}^{-1}\)</span>. Then the solution of the linear system in abstract notation would just be</p>
<p><span class="math display">\[\mathbf{x} = \mathbf{A}^{-1} \mathbf{b}.\]</span></p>
<p>This is the most general kind of solution we could write for a square linear system. Of course, the real hard part in solving a general <span class="math inline">\(n \times n\)</span> system is finding what exactly <span class="math inline">\(\mathbf{A}^{-1}\)</span> is.</p>
<p>But why did I use the notation <span class="math inline">\(\mathbf{A}^{-1}\)</span> for this matrix? Because it’s in some sense a way to “divide” by a matrix. Recall in the <span class="math inline">\(1 \times 1\)</span> case where <span class="math inline">\(ax=b\)</span> the solution looked like <span class="math inline">\(x=a^{-1}b\)</span>. In that case, <span class="math inline">\(a^{-1}\)</span> was literally the inverse of the number <span class="math inline">\(a\)</span>, since <span class="math inline">\(aa^{-1} = a^{-1}a = 1\)</span>. It turns out the matrix <span class="math inline">\(\mathbf{A}^{-1}\)</span> is the higher-dimensional generalization of <span class="math inline">\(a^{-1}\)</span>. It’s called the <strong>inverse</strong> of <span class="math inline">\(\mathbf{A}\)</span>. To see why, notice in the <span class="math inline">\(2 \times 2\)</span> case if we multiply <span class="math inline">\(\mathbf{A}\mathbf{A}^{-1}\)</span>, we’d have</p>
<p><span class="math display">\[
\mathbf{A}\mathbf{A}^{-1} =
\begin{pmatrix}
a &amp; b \\
c &amp; d
\end{pmatrix}
\begin{pmatrix}
\frac{d}{ad-bc} &amp; -\frac{b}{ad-bc} \\
-\frac{c}{ad-bc} &amp; \frac{a}{ad-bc}
\end{pmatrix} =
\begin{pmatrix}
\frac{ad}{ad-bc}-\frac{bc}{ad-bc} &amp; -\frac{ab}{ad-bc}+\frac{ab}{ad-bc} \\
\frac{cd}{ad-bc}-\frac{dc}{ad-bc} &amp; -\frac{cb}{ad-bc}+\frac{da}{ad-bc}
\end{pmatrix} =
\begin{pmatrix}
\frac{ad-bc}{ad-bc} &amp; \frac{ab-ab}{ad-bc} \\
\frac{cd-cd}{ad-bc} &amp; \frac{ad-bc}{ad-bc}
\end{pmatrix} =
\begin{pmatrix}
1 &amp; 0 \\
0 &amp; 1
\end{pmatrix}.
\]</span></p>
<p>I’ll write the matrix on the right as <span class="math inline">\(\mathbf{I}\)</span>. It’s called the <strong>identity matrix</strong>. It’s evidently the matrix generalization of the number <span class="math inline">\(1\)</span>. What I’ve just shown is that <span class="math inline">\(\mathbf{A}^{-1}\)</span> “undoes” <span class="math inline">\(\mathbf{A}\)</span> in the sense that <span class="math inline">\(\mathbf{A}\mathbf{A}^{-1} = \mathbf{I}\)</span>. Of course, since matrix multiplication doesn’t commute, this says nothing about what the reverse product <span class="math inline">\(\mathbf{A}^{-1}\mathbf{A}\)</span> is. You can check in the <span class="math inline">\(2 \times 2\)</span> case that indeed we’d get <span class="math inline">\(\mathbf{A}^{-1}\mathbf{A} = \mathbf{I}\)</span> as well. That is, <span class="math inline">\(\mathbf{A}^{-1}\)</span> is a two-sided inverse. A matrix and its inverse always commute.</p>
<p>Notice that in the <span class="math inline">\(2 \times 2\)</span> case, the inverse matrix <span class="math inline">\(\mathbf{A}^{-1}\)</span> includes a division by the determinant <span class="math inline">\(\det(\mathbf{A})\)</span>,</p>
<p><span class="math display">\[
\mathbf{A}^{-1} =
\frac{1}{ad-bc}
\begin{pmatrix}
d &amp; -b \\
-c &amp; a
\end{pmatrix} =
\frac{1}{\det(\mathbf{A})}
\begin{pmatrix}
d &amp; -b \\
-c &amp; a
\end{pmatrix}.
\]</span></p>
<p>Evidently, the inverse matrix only exists when <span class="math inline">\(\det(\mathbf{A}) \neq 0\)</span>, since otherwise the matrix would blow up due to division by zero. This is a general statement. For any <span class="math inline">\(n \times n\)</span> matrix, its inverse exists if and only if its determinant is non-zero. For this reason, we say a square matrix with a non-zero determinant is <strong>invertible</strong>. If the determinant <em>is</em> zero, we call the matrix <strong>singular</strong>.</p>
<p>Of course, it’s no longer obvious at all how to even find <span class="math inline">\(\mathbf{A}^{-1}\)</span> or <span class="math inline">\(\text{det}(\mathbf{A})\)</span> when <span class="math inline">\(n\)</span> is greater than <span class="math inline">\(2\)</span> or <span class="math inline">\(3\)</span>. Thankfully, we don’t really need to know the gritty details of how to find these things. Just know that algorithms exist to calculate them. I’ll talk at a high level about how those algorithms work in a future lesson.</p>
<p>In numpy, you can solve a square linear system <span class="math inline">\(\mathbf{A}\mathbf{x} = \mathbf{b}\)</span> by using the command <code>np.linalg.solve(A, b)</code>. While you <em>could</em> also solve a system by first calculating the inverse and then taking <span class="math inline">\(\mathbf{x} = \mathbf{A}^{-1} \mathbf{b}\)</span>, this turns out to be a bad idea to do numerically. It’s actually better to avoid explicitly calculating <span class="math inline">\(\mathbf{A}^{-1}\)</span> unless you absolutely need it. The main reason is the inverse computation turns out to be highly prone to numerical loss of precision. Nevertheless, if you do need the inverse for some reason, you can get it with <code>np.linalg.inv(A)</code>. Just like matrix multiplication, both of these functions are cubic time algorithms.</p>
<p>Here’s an example. I’ll solve the <span class="math inline">\(3 \times 3\)</span> linear system below using <code>np.solve</code>. To do this, I’ll first need to convert everything to matrix-vector notation,</p>
<p><span class="math display">\[\begin{gather*}
\begin{alignedat}{5}
   x_0 &amp; {}+{} &amp;  2x_1 &amp; {}+{} &amp; 3x_2 {}={} &amp; 1 \\
   4x_0 &amp; {}+{} &amp;  5x_1 &amp; {}-{} &amp; 6x_2 {}={} &amp; 1 \\
   7x_0 &amp; {}-{} &amp;  8x_1 &amp; {}-{} &amp; 9x_3 {}={} &amp; 1. \\
\end{alignedat}
\quad \Longrightarrow \quad
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6 \\
7 &amp; 8 &amp; 9 \\
\end{pmatrix}
\begin{pmatrix}
x_0 \\
x_1 \\
x_2 \\
\end{pmatrix} =
\begin{pmatrix}
1 \\
1 \\
1 \\
\end{pmatrix}.
\end{gather*}\]</span></p>
<div class="cell" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>], [<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>]])<span class="op">;</span> <span class="bu">print</span>(<span class="ss">f'A = </span><span class="ch">\n</span><span class="sc">{</span>A<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.array([[<span class="dv">1</span>], [<span class="dv">1</span>], [<span class="dv">1</span>]])<span class="op">;</span> <span class="bu">print</span>(<span class="ss">f'b = </span><span class="ch">\n</span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linalg.solve(A, b)<span class="op">;</span> <span class="bu">print</span>(<span class="ss">f'x = </span><span class="ch">\n</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>A = 
[[1 2 3]
 [4 5 6]
 [7 8 9]]
b = 
[[1]
 [1]
 [1]]
x = 
[[ 0.2]
 [-1.4]
 [ 1.2]]</code></pre>
</div>
</div>
<p>Here’s the determinant and inverse of this matrix. Notice how close it is to being non-singular, since <span class="math inline">\(\det(\mathbf{A}) \approx -10^{-15}\)</span> is tiny. This small determinant causes the inverse to be huge, with terms on the order of <span class="math inline">\(10^{15}\)</span>. This is where you can start to see the loss of precision creeping in. If we calculate <span class="math inline">\(\mathbf{A}\mathbf{A}^{-1}\)</span> we won’t get anything looking like the identity matrix. Yet, using <code>np.solve</code> worked just fine. Multiply <span class="math inline">\(\mathbf{A}\mathbf{x}\)</span> and you’ll get exactly <span class="math inline">\(\mathbf{b}\)</span> back.</p>
<div class="cell" data-execution_count="20">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'det(A) = </span><span class="sc">{</span>np<span class="sc">.</span>linalg<span class="sc">.</span>det(A)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'A^(-1) = </span><span class="ch">\n</span><span class="sc">{</span>np<span class="sc">.</span>linalg<span class="sc">.</span>inv(A)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'A A^(-1) = </span><span class="ch">\n</span><span class="sc">{</span>A <span class="op">@</span> np<span class="sc">.</span>linalg<span class="sc">.</span>inv(A)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>det(A) = -9.51619735392994e-16
A^(-1) = 
[[ 3.15251974e+15 -6.30503948e+15  3.15251974e+15]
 [-6.30503948e+15  1.26100790e+16 -6.30503948e+15]
 [ 3.15251974e+15 -6.30503948e+15  3.15251974e+15]]
A A^(-1) = 
[[ 0.  1.  0.]
 [ 0.  2.  0.]
 [-4.  3.  2.]]</code></pre>
</div>
</div>
</section>
<section id="rectangular-systems" class="level3" data-number="5.4.2">
<h3 data-number="5.4.2" class="anchored" data-anchor-id="rectangular-systems"><span class="header-section-number">5.4.2</span> Rectangular Systems</h3>
<p>Everything I just covered applies only to <em>square</em> linear systems, where there are exactly as many equations as there are unknowns. In real life, the systems of equations we care about solving are rarely square. For example, in machine learning we’re usually dealing with matrices of data, where the rows represent the number of samples and the columns represent the number of features in the data. It’ll almost never be the case that we have exactly the same number of samples as we have features.</p>
<p>A <em>rectangular</em> system is an <span class="math inline">\(m \times n\)</span> linear system <span class="math inline">\(\mathbf{A}\mathbf{x} = \mathbf{b}\)</span> where <span class="math inline">\(m \neq n\)</span>. That is, the number of equations is different from the number of unknowns. Evidently there are two distinct cases to consider here:</p>
<ol type="1">
<li>More equations than unknowns (<span class="math inline">\(m &gt; n\)</span>): These are called <strong>over-determined</strong> systems. In an over-determined system, we have too many equations. It’ll usually be impossible to solve them all exactly.</li>
<li>More unknowns than equations (<span class="math inline">\(m &lt; n\)</span>): These are called <strong>under-determined</strong> systems. In an under-determined system, we don’t have enough equations. There will always be infinitely many ways to solve these kinds of systems.</li>
</ol>
<section id="over-determined-systems" class="level4" data-number="5.4.2.1">
<h4 data-number="5.4.2.1" class="anchored" data-anchor-id="over-determined-systems"><span class="header-section-number">5.4.2.1</span> Over-Determined Systems</h4>
<p>In either case, <span class="math inline">\(\mathbf{A}\)</span> won’t have a two-sided inverse anymore, nor will it have a determinant. What do we do? Let’s again start small. Let’s first look at a simple over-determined system, a <span class="math inline">\(3 \times 2\)</span> system. Consider the following example.</p>
<p><span class="math display">\[\begin{gather*}
\begin{alignedat}{3}
   2x_0 &amp; {}+{} &amp;  x_1 {}={} &amp; -1 \\
   -3x_0 &amp; {}+{} &amp;  x_1 {}={} &amp; -2 \\
   -x_0 &amp; {}-{} &amp;  x_1 {}={} &amp; 1. \\
\end{alignedat}
\quad \Longrightarrow \quad
\begin{pmatrix}
2 &amp; 1 \\
-3 &amp; 1 \\
-1 &amp; 1 \\
\end{pmatrix}
\begin{pmatrix}
x_0 \\
x_1 \\
\end{pmatrix} =
\begin{pmatrix}
-1 \\
-2 \\
1 \\
\end{pmatrix}.
\end{gather*}\]</span></p>
<p>Graphically, this system corresponds to 3 lines in the plane. Let’s plot them and see what’s going on. The equations for the lines are,</p>
<p><span class="math display">\[\begin{align*}
y &amp;= -1 - 2x, \\
y &amp;= -2 + 3x, \\
y &amp;= 1 + x. \\
\end{align*}\]</span></p>
<div class="cell" data-execution_count="21">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>, <span class="dv">100</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>f0 <span class="op">=</span> <span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">1</span> <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> x</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> <span class="kw">lambda</span> x: <span class="op">-</span><span class="dv">2</span> <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> x</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>f2 <span class="op">=</span> <span class="kw">lambda</span> x: <span class="dv">1</span> <span class="op">+</span> x</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>plot_function(x, [f0, f1, f2], xlim<span class="op">=</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>), ylim<span class="op">=</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>), </span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>              title<span class="op">=</span><span class="st">'3 Linear Equations, 2 Unknowns'</span>,</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>              labels<span class="op">=</span>[<span class="ss">f'$y=-1-2x$'</span>, <span class="ss">f'$y=-2-3x$'</span>, <span class="ss">f'$y=1-x$'</span>], </span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>              legend_fontsize<span class="op">=</span><span class="fl">9.5</span>, legend_loc<span class="op">=</span><span class="st">'upper left'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="linear-systems_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>From the plot, we can see that the three lines don’t all intersect at the same point, which means there’s no single solution that satisfies this particular system. In fact, this is general. It’s <em>very</em> unlikely that more than two lines will intersect at the same point, or more than three planes will intersect at the same point, etc.</p>
<p>So what do we do? If we can’t find an <em>exact</em> solution, can we at least find an <em>approximately good</em> solution? Yes we can. Let’s look at the situation abstractly for a minute. Suppose <span class="math inline">\(\mathbf{A}\mathbf{x} = \mathbf{b}\)</span> describes the over-determined example given above. Then <span class="math inline">\(\mathbf{A}\)</span> is a <span class="math inline">\(3 \times 2\)</span> matrix. We can’t invert it, nor can we take its determinant. But we can find a way “squarify it” somehow. To do that, I’ll need to introduce the <em>transpose</em> operation.</p>
<p>If <span class="math inline">\(\mathbf{A}\)</span> is some <span class="math inline">\(m \times n\)</span> matrix, either square or rectangular, we can swap its rows and columns to get an <span class="math inline">\(n \times m\)</span> matrix that’s somehow related to <span class="math inline">\(\mathbf{A}\)</span>. This swapped matrix is called the <strong>transpose</strong> of <span class="math inline">\(\mathbf{A}\)</span>. It’s usually denoted by the symbol <span class="math inline">\(\mathbf{A}^\top\)</span>, read “A transpose”. Formally, it’s defined by</p>
<p><span class="math display">\[A_{i,j}^\top = A_{j,i}.\]</span></p>
<p>In the above example, we’d have</p>
<p><span class="math display">\[
\mathbf{A} =
\begin{pmatrix}
2 &amp; 1 \\
-3 &amp; 1 \\
-1 &amp; 1 \\
\end{pmatrix} \quad \Longrightarrow \quad
\mathbf{A}^\top =
\begin{pmatrix}
2 &amp; -3 &amp; 1 \\
1 &amp; 1 &amp; 1 \\
\end{pmatrix}.
\]</span></p>
<p>All I did was swap the rows and columns. That’s all the transpose operation is doing. Since <span class="math inline">\(\mathbf{A}\)</span> in this example is <span class="math inline">\(3 \times 2\)</span>, <span class="math inline">\(\mathbf{A}^\top\)</span> must be <span class="math inline">\(2 \times 3\)</span>.</p>
<p>The transpose gives us an interesting and sensible way to “squarify” a matrix. Consider what happens when we left multiply an <span class="math inline">\(m \times n\)</span> matrix <span class="math inline">\(\mathbf{A}\)</span> by its transpose. Evidently the product <span class="math inline">\(\mathbf{A}^\top \mathbf{A}\)</span> would have to be an <span class="math inline">\(n \times n\)</span> matrix. That is, it’s square. In the above example, we’d get the <span class="math inline">\(2 \times 2\)</span> matrix</p>
<p><span class="math display">\[
\mathbf{A}^\top \mathbf{A} =
\begin{pmatrix}
14 &amp; -2 \\
-2 &amp; 3 \\
\end{pmatrix}.
\]</span></p>
<p>Here’s what this looks like in numpy. We can get the transpose of a matrix <code>A</code> by using either the method <code>A.T</code> or the function <code>np.transpose(A)</code>.</p>
<div class="cell" data-execution_count="22">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">2</span>, <span class="dv">1</span>], </span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    [<span class="op">-</span><span class="dv">3</span>, <span class="dv">1</span>], </span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    [<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>]])</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>At <span class="op">=</span> A.T</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>AtA <span class="op">=</span> At <span class="op">@</span> A</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'A = </span><span class="ch">\n</span><span class="sc">{</span>A<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'A.T = </span><span class="ch">\n</span><span class="sc">{</span>At<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'A.T A = </span><span class="ch">\n</span><span class="sc">{</span>AtA<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>A = 
[[ 2  1]
 [-3  1]
 [-1  1]]
A.T = 
[[ 2 -3 -1]
 [ 1  1  1]]
A.T A = 
[[14 -2]
 [-2  3]]</code></pre>
</div>
</div>
<p>Now, let’s go back to the over-determined system <span class="math inline">\(\mathbf{A}\mathbf{x} = \mathbf{b}\)</span>. If we left-multiply both sides by <span class="math inline">\(\mathbf{A}^\top\)</span>, we’d get</p>
<p><span class="math display">\[\mathbf{A}^\top \mathbf{A}\mathbf{x} = \mathbf{A}^\top \mathbf{b}.\]</span></p>
<p>Most of the time, the square matrix <span class="math inline">\(\mathbf{A}^\top \mathbf{A}\)</span> will be invertible. Provided that’s the case, we can write</p>
<p><span class="math display">\[\mathbf{x} \approx (\mathbf{A}^\top \mathbf{A})^{-1} \mathbf{A}^\top \mathbf{b}.\]</span></p>
<p>I use approximately equals here because this won’t usually give the <em>exact</em> solution to <span class="math inline">\(\mathbf{A}\mathbf{x} = \mathbf{b}\)</span>. But it does give in some sense the best approximate solution you can get. For reasons I won’t go into much right this moment, this kind of approximate solution is called the <strong>least squares solution</strong> to the linear system. It’s the solution that minimizes the weird looking term <span class="math inline">\((\mathbf{A}\mathbf{x} - \mathbf{b})^\top (\mathbf{A}\mathbf{x} - \mathbf{b})\)</span>, whatever that means.</p>
<p>In numpy, we can’t use <code>np.linalg.solve(A, b)</code> when a linear system isn’t square. If we want to find the least squares solution, we’ll need to use the function <code>np.linalg.lstsq(A, b)</code> instead. This function actually returns a lot more stuff than just the <code>x</code> we seek. For now I’ll ignore those other objects and show you what the least squares solution to the above <span class="math inline">\(3 \times 2\)</span> system looks like. Evidently, it’s</p>
<p><span class="math display">\[
\mathbf{x} \approx
\begin{pmatrix}
0.136 \\
-0.578 \\
\end{pmatrix}.
\]</span></p>
<p>If you go back to the previous plot, you’ll see this point seems to lie close to the point where the blue and orange lines intersect. That’s interesting.</p>
<div class="cell" data-execution_count="23">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.array([[<span class="op">-</span><span class="dv">1</span>], [<span class="op">-</span><span class="dv">2</span>], [<span class="dv">1</span>]])</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>x, _, _, _ <span class="op">=</span> np.linalg.lstsq(A, b)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'x ≈ </span><span class="ch">\n</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>x ≈ 
[[ 0.13157895]
 [-0.57894737]]</code></pre>
</div>
</div>
<p>Let’s look again at the least squares solution <span class="math inline">\(\mathbf{x} \approx (\mathbf{A}^\top \mathbf{A})^{-1} \mathbf{A}^\top \mathbf{b}\)</span>. Notice that the matrix <span class="math inline">\((\mathbf{A}^\top \mathbf{A})^{-1} \mathbf{A}^\top\)</span> seems to function kind of like <span class="math inline">\(\mathbf{A}^{-1}\)</span>, if it existed. For this reason, it’s called the <strong>pseudoinverse</strong> of <span class="math inline">\(\mathbf{A}\)</span>, usually denoted by the special symbol <span class="math inline">\(\mathbf{A}^+\)</span>. The pseudoinverse is in some sense the closest we can get to inverting the matrix of an over-determined system. Evidently, it satisfies the property that it’s a <em>left</em> inverse of <span class="math inline">\(\mathbf{A}\)</span>,</p>
<p><span class="math display">\[\mathbf{A}^+ \mathbf{A} = \mathbf{I}.\]</span></p>
</section>
<section id="under-determined-systems" class="level4" data-number="5.4.2.2">
<h4 data-number="5.4.2.2" class="anchored" data-anchor-id="under-determined-systems"><span class="header-section-number">5.4.2.2</span> Under-Determined Systems</h4>
<p>I’ll come back to this more later. Let’s briefly take a look at the other type of rectangular system, the <em>over-determined</em> system where <span class="math inline">\(m &lt; n\)</span>. In this case there are too many unknowns and not enough equations. As an example, consider the following <span class="math inline">\(2 \times 3\)</span> linear system,</p>
<p><span class="math display">\[\begin{gather*}
\begin{alignedat}{3}
   x_0 &amp; {}+{} &amp;  x_1 &amp; {}+{} &amp; x_2 {}={} &amp; 2  \\
   x_0 &amp; {}-{} &amp;  x_1 &amp; {}+{} &amp; x_2 {}={} &amp; 0 \\
\end{alignedat}
\quad \Longrightarrow \quad
\begin{pmatrix}
1 &amp; 1 &amp; 1 \\
1 &amp; -1 &amp; 1 \\
\end{pmatrix}
\begin{pmatrix}
x_0 \\
x_1 \\
x_2 \\
\end{pmatrix} =
\begin{pmatrix}
2 \\
0 \\
\end{pmatrix}.
\end{gather*}\]</span></p>
<p>Graphically, this system will look like two planes in 3D space,</p>
<p><span class="math display">\[\begin{align*}
z &amp;= 2 - x - y, \\
z &amp;= -x + y. \\
\end{align*}\]</span></p>
<p>Since there are two planes, they’ll intersect not at a point, but at a line. Any point on this line will be a solution to the linear system.</p>
<div class="cell" data-execution_count="24">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">100</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> np.linspace(<span class="op">-</span><span class="fl">1.9</span>, <span class="fl">3.9</span>, <span class="dv">100</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> <span class="kw">lambda</span> x, y: <span class="dv">2</span> <span class="op">-</span> x <span class="op">-</span> y</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>f2 <span class="op">=</span> <span class="kw">lambda</span> x, y: y <span class="op">-</span> x</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>plot_function_3d(x, y, [f1, f2], azim<span class="op">=</span><span class="dv">30</span>, elev<span class="op">=</span><span class="dv">20</span>, ticks_every<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>], figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>), zorders<span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>], dist<span class="op">=</span><span class="dv">12</span>,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>        colors<span class="op">=</span>[<span class="st">'steelblue'</span>, <span class="st">'limegreen'</span>], alpha<span class="op">=</span><span class="fl">0.6</span>, titlepad<span class="op">=-</span><span class="dv">5</span>, labelpad<span class="op">=</span><span class="dv">2</span>, title<span class="op">=</span><span class="st">'2 Equations, 3 Unknowns'</span>,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>        lines<span class="op">=</span>[[<span class="dv">1</span> <span class="op">-</span> t, np.full(<span class="bu">len</span>(t), <span class="dv">1</span>), t]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="linear-systems_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>To see why this system has infinitely many solutions, let’s try to solve it. It’s easy enough using substitution. The second equation says <span class="math inline">\(x_1 = x_0 + x_2\)</span>. Plugging this into the first equation then says <span class="math inline">\(x_2 = 1 - x_0\)</span>. There’s no way to solve for <span class="math inline">\(x_0\)</span> because we don’t have enough equations. We thus have to conclude that the solutions to this system look like</p>
<p><span class="math display">\[x_0 = x_0, \quad x_1 = 1, \quad x_2 = 1 - x_0.\]</span></p>
<p>Any choice of <span class="math inline">\(x_0\)</span> will satisfy this linear system, which means it’ll have infinitely many solutions, which are of course just the points on the line above.</p>
<p>In general, we can almost exactly the same trick to “solve” these linear systems as we did with the over-determined systems. This time, instead of multiplying <span class="math inline">\(\mathbf{A}\)</span> on the <em>left</em> by <span class="math inline">\(\mathbf{A}^\top\)</span>, we’ll instead multiply on the <em>right</em> by <span class="math inline">\(\mathbf{A}^\top\)</span>,</p>
<p><span class="math display">\[\mathbf{A}\mathbf{A}^\top \mathbf{x} = \mathbf{A}^\top \mathbf{b}.\]</span></p>
<p>Provided we can invert <span class="math inline">\(\mathbf{A}\mathbf{A}^\top\)</span>, and usually we can, we’ll get a solution of the form</p>
<p><span class="math display">\[\mathbf{x} = (\mathbf{A}\mathbf{A}^\top)^{-1} \mathbf{A}^\top \mathbf{b}.\]</span></p>
<p>Note that this gives only <em>one</em> of the infinitely many possible solutions to an under-determined linear system. For reasons I won’t go into now, it turns out the solution it gives is called the <strong>least norm</strong> solution. In a sense, this means it gives you the “smallest” vector <span class="math inline">\(\mathbf{x}\)</span> that satisfies <span class="math inline">\(\mathbf{A}\mathbf{x} = \mathbf{b}\)</span>. By smallest, I mean it’s the vector such that the <span class="math inline">\(1 \times 1\)</span> matrix <span class="math inline">\(\mathbf{x}^\top \mathbf{x}\)</span> is minimized.</p>
<p>It turns out the matrix <span class="math inline">\((\mathbf{A}\mathbf{A}^\top)^{-1} \mathbf{A}^\top\)</span> on the right is <em>also</em> a pseudoinverse. It satisfies the property that it’s a <em>right</em> inverse of <span class="math inline">\(\mathbf{A}\)</span>, in the sense that</p>
<p><span class="math display">\[\mathbf{A} \mathbf{A}^+ = \mathbf{I}.\]</span></p>
<p>In fact, there are many different kinds of pseudoinverses. The two I covered here are the most practical ones.</p>
<p>In numpy, you can solve an under-determined system by using the same <code>np.linalg.lstsq(A, b)</code> function from before. It’s able to tell which case you want by looking at the shape of the <code>A</code> you pass in. Here’s the least norm solution for the above example,</p>
<p><span class="math display">\[
\mathbf{x} =
\begin{pmatrix}
\frac{1}{2} \\
1 \\
\frac{1}{2} \\
\end{pmatrix}.
\]</span></p>
<p>You can check it satisfies the linear system with the choice of <span class="math inline">\(x_0 = \frac{1}{2}\)</span>.</p>
<div class="cell" data-execution_count="25">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> np.array([</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>], </span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>]])</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.array([[<span class="dv">2</span>], [<span class="dv">0</span>]])</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>x, _, _, _ <span class="op">=</span> np.linalg.lstsq(A, b)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'x ≈ </span><span class="ch">\n</span><span class="sc">{</span>x<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>x ≈ 
[[0.5]
 [1. ]
 [0.5]]</code></pre>
</div>
</div>
<p>I’ll come back to this stuff more in later lessons and fill in some of these missing pieces. I just want to close by mentioning that I’ve essentially just derived much of the ideas behind linear regression in this section. In fact, training a linear regression model is completely equivalent to finding either a least squares solution or a least norm solution to <span class="math inline">\(\mathbf{A}\mathbf{x} = \mathbf{b}\)</span>. In that case, <span class="math inline">\(\mathbf{A}\)</span> represents the matrix of data, <span class="math inline">\(\mathbf{x}\)</span> represents the parameters the model needs to learn, and <span class="math inline">\(\mathbf{b}\)</span> represents the target values. Using what I’ve covered in this lesson, you could completely solve any linear regression problem you wanted from scratch just by using something like <code>x = np.linalg.lstsq(A, b)</code>.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-page-right">
  <div class="nav-page nav-page-previous">
      <a href="../notebooks/calculus.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Calculus</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notebooks/vectors.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Vector Spaces</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>